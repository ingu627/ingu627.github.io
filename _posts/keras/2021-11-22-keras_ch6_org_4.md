---
layout: single
title: "[케라스(keras) 이해] 6장. 텍스트와 시퀀스를 위한 딥러닝 (4)"
excerpt: "케라스 창시자에게 배우는 딥러닝 - 컨브넷을 사용한 시퀀스 처리"
categories: keras
tag : [python, keras, DL, ML, AI, 인고지능, 딥러닝, 케라스, 시퀀스, CNN, RNN]
toc: true
sidebar_main: true
classes: wide

last_modified_at: 2021-12-29
---

<img align='right' width='200' height='200' src='https://user-images.githubusercontent.com/78655692/147629300-4d7acc5e-225a-454a-92cd-4da82f6828f6.png
'>
본 글은 [케라스 창시자에게 배우는 딥러닝] - (박해선 옮김) 책을 개인공부하기 위해 요약, 정리한 내용입니다. <br>전체 코드는 [https://github.com/ingu627/deep-learning-with-python-notebooks](https://github.com/ingu627/deep-learning-with-python-notebooks)에 기재했습니다.(원본 코드 fork) <br> 뿐만 아니라 책에서 설명이 부족하거나 이해가 안 되는 것들은 외부 자료들을 토대로 메꿔 놓았습니다. 즉, 딥러닝은 이걸로 끝을 내보는 겁니다. <br> 오타나 오류는 알려주시길 바라며, 도움이 되길 바랍니다.
{: .notice--info}

<br>
<br>
<br>
<br>

## 6_4. 컨브넷을 사용한 시퀀스 처리

- **1D 컨브넷**(1D Convnet)은 특정 시퀀스 처리 문제에서 RNN과 결줄 만한다.
- 일반적으로 계산 비용이 훨씬 싸다.
- 1D 컨브넷은 전형적으로 **팽창된 커널**(dilated kernel)과 함께 사용된다.
  - **팽창 합성곱**은 커널에 구멍을 추가하여 입력을 건너뛰면서 합성곱하는 것과 같다.
- **1D 합성곱** : 시퀀스에서 1D 패치(부분 시퀀스)를 추출하여 1D 합성곱을 적용한다.

<img src="https://user-images.githubusercontent.com/78655692/142854777-41f8c287-0473-48d4-8943-bd7be31bad0b.png" width="500" height="400" alt="동작 원리" />

- 이런 1D 합성곱 층은 시퀀스에 있는 지역 패턴을 인식할 수 있다.
- 동일한 변환이 시퀀스에 있는 모든 패치에 적용되기 때문에 특정 위치에서 학스한 패턴을 나중에 다른 위치에서 인식할 수 있다.
- 이는 **1D 컨브넷**(시간의 이동에 대한) 이동 불변성(translation invariant)을 제공한다. 
  - 예를 들어 크기 5인 윈도우를 사용하여 문자 시퀀스를 처리하는 1D 컨브넷은 5개 이하의 단어나 단어의 부분을 학습한다.
  - 이 컨브넷은 이 단어가 입력 시퀀스의 어느 문장에 있더라도 인식할 수 있다.
  - 따라서 문자 수준의 1D 컨브넷은 단어 형태학(word morphology)에 관해 학습할 수 있다.
- 1D 풀링 연산은 2D 풀링 연산과 동일하다. 입력에서 1D 패치(부분 시퀀스)를 추출하고 최댓값(최대 풀링)을 출력하거나 평균값(평균 풀링)을 출력한다.
- 2D 컨브넷과 마찬가지로 1D 입력의 길이를 줄이기 위해 사용한다. (서브샘플링)

## 6_4_3. 1D 컨브넷 구현 

- 케라스에서 1D 컨브넷은 Conv1D 층을 사용하여 구현한다.
- (samples, time, features) 크기의 3D 텐서를 입력받고 비슷한 형태의 3D 텐서를 반환한다. 
- **합성곱 윈도우**는 1D 윈도우이다. 즉, 입력 텐서의 두 번째 축이다.

### IMDB 데이터 전처리하기 

<script src="https://gist.github.com/ingu627/e7f2794e87d5860fc172ab2555c294be.js"></script>

### IMDB 데이터에 1D 컨브넷을 훈련하고 평가받기

<script src="https://gist.github.com/ingu627/fcb2770b9933c658413003a195554dd0.js"></script>

- Conv1D와 MaxPooling1D층을 쌓고 전역 풀링 층이나 Flatten 층으로 마친다.
  - **GlobalAveragePooling1D**, **GlobalMaxPooling1D**은 (sammples, timesteps, features) 크기의 텐서를 입력받고 (samples, features) 크기의 텐서를 출력한다. 즉 시간 축 전체에 풀링을 적용한다.
  - **GlobalAveragePooling2D**, **GlobalMaxPooling2D** 풀링은 (samples, height, width, channels) 크기의 텐서를 입력받고 (samples, channels) 크기의 텐서를 출력한다. 즉 특성 맵의 공간 차원 전체에 대한 풀링이다.
- 이 구조는 3D 입력을 2D 출력으로 바꾸므로 분류나 회귀를 위해 모델에 하나 이상의 Dense 층을 추가할 수 있다.

![image](https://user-images.githubusercontent.com/78655692/142859707-a26439ee-fe83-4577-b15b-c388e4ac41db.png)

## 6_4_4. CNN과 RNN을 연결하여 긴 시퀀스를 처리하기 

- 1D 컨브넷이 입력 패치를 독립적으로 처리하기 때문에 RNN과 달리 (합성곱 윈도우 크기의 범위를 넘어서는) 타임스탭의 순서에 민감하지 않다.
- 물론 장기간 패턴을 인식하기 위해 많은 합성곱 층과 풀링 층을 쌓을 수 있다.
- 컨브넷의 속도와 경량함을 RNN의 순서 감지 능력과 결합하는 한 가지 전략은 1D 컨브넷을 RNN 이전에 전처리 단계로 사용하는 것이다.
  - 수천 개의 스텝을 가진 시퀀스 같이 RNN으로 처리하기에는 현실적으로 너무 긴 시퀀스를 다룰 때 특별히 도움이 된다.
  - 컨브넷이 긴 입력 시퀀스를 더 짧은 고수준 특성의 (다운샘플된) 시퀀스로 변환한다.
  - 추출된 특성의 시퀀스는 RNN 파트의 입력이 된다.

<img src="https://user-images.githubusercontent.com/78655692/142860349-542446c7-1441-4e82-b439-854d9b3eb45f.png" width="500" height="400" alt="결합 동작 원리" />



## References

- [케라스 창시자에게 배우는 딥러닝](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=173992478) 