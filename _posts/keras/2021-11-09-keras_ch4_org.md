---
layout: single
title: "케라스 4장: 머신러닝 기본 요소 - 일반화·과적합·정규화 이해"
excerpt: "케라스 창시자에게 배우는 딥러닝 - 머신 러닝의 네 가지 분류"
categories: keras
tags: [python, keras, DL, ML, AI, 인고지능, 딥러닝, 케라스, 머신러닝, 리뷰, 정리, 이해, 모델, 케라스 창시자에게 배우는 딥러닝]
toc: true
sidebar_main: false
classes: wide

last_modified_at: 2025-09-27
---

<img align='right' width='200' height='200' src='https://user-images.githubusercontent.com/78655692/147629300-4d7acc5e-225a-454a-92cd-4da82f6828f6.png
'>
본 글은 [케라스 창시자에게 배우는 딥러닝] - (박해선 옮김) 책을 개인공부하기 위해 요약, 정리한 내용입니다. <br>전체 코드는 [https://github.com/ingu627/deep-learning-with-python-notebooks](https://github.com/ingu627/deep-learning-with-python-notebooks)에 기재했습니다.(원본 코드 fork) <br> 뿐만 아니라 책에서 설명이 부족하거나 이해가 안 되는 것들은 외부 자료들을 토대로 메꿔 놓았습니다. 즉, 딥러닝은 이걸로 끝을 내보는 겁니다. <br> 오타나 오류는 알려주시길 바라며, 도움이 되길 바랍니다.
{: .notice--info}

<br>

## 4_1. 머신 러닝의 네 가지 분류

- 지도 학습, 비지도 학습, 자기 지도 학습, 강화 학습

<br>

### 4_1_1. 지도 학습

- 샘플 데이터가 주어지면 알고 있는 타깃에 입력 데이터를 매핑하는 방법을 학습한다.

<br>

### 4_1_2. 비지도 학습

- 어떤 타깃도 사용하지 않고 입력 데이터의 변환을 찾는다.
  - 차원 축소 (dimensionality)와 군집( clustering)이 그 예

<br>

### 4_1_3. 자기 지도 학습 

- 자기 지도 학습은 지도 학습이지만 사람이 만든 레이블을 사용하지 않는다. 
- 보통 경험적인 알고리즘 (heuristic algorithm)을 사용해서 입력 데이터로부터 생성한다.
  - 오토인코더 (autoencoder)가 그 예

<br>

### 4_1_4. 강화 학습

- 강화 학습에서 에이전트 (agent)는 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 학습한다.

<br>

### 분류와 회귀에서 사용하는 용어

- **샘플** 또는 **입력** : 모델에 주입될 하나의 데이터 포인트
- **예측** 또는 **출력** : 모델로부터 나오는 값
- **타깃** : 정답. 외부 데이터 소스에 근거하여 모델이 완벽하게 예측해야 하는 값
- **예측 오차** 또는 **손실 값** : 모델의 예측과 타깃 사이의 거리를 측정한 값
- **클래스** : 분류 문제에서 선택할 수 있는 가능한 레이블의 집합.
  - 예를 들어 고양이와 강아지 사진을 분류할 때 클래스는 '고양이'와 '강아지' 2개이다.
- **레이블** : 분류 문제에서 선택할 수 있는 가능한 레이블의 집합.
  - 예를 들어 사진 #1234에 '강아지' 클래스가 들어 있다고 표시하면 '강아지'는 사진#1234의 레이블이 된다.
- **꼬리표**(annotation) : 데이터셋에 대한 모든 타깃. 일반적으로 사람에 의해 수집된다.
- **이진 분류** : 각 입력 샘플이 2개의 배타적인 범주로 구분되는 분류 작업
- **다중 분류** : 각 입력 샘플이 2개 이상의 범주로 구분되는 분류 작업. 예를 들어 손글씨 숫자 분류
- **다중 레이블 분류** : 각 입력 샘플이 여러 개의 레이블에 할당될 수 있는 분류 작업 
  - 예를 들어 하나의 이미지에 고양이와 강아지가 모두 들어 있을 때는 '고양이' 레이블과 '강아지' 레이블을 모두 할당해야 한다.
- **스칼라 회귀** : 타깃이 연속적인 스칼라 값인 작업. 주택 가격이 예측이 그 예 
- **벡터 회귀** : 타깃이 연속적인 값의 집합인 작업.
- **미니 배치** 또는 **배치** : <b><span style="color:red">모델에 의해 동시에 처리되는 소량의 샘플 묶음(일반적으로 8개에서 128개 사이)</span></b>
  - <u>샘플 개수는 GPU의 메모리 할당이 용이하도록 2의 거듭제곱으로 하는 경우가 많다.</u>
  - 훈련할 때 미니 배치마다 한 번씩 모델의 가중치에 적용할 경사 하강법 업데이트 값을 계산한다.

<br>

## 4_2. 머신 러닝 모델 평가

- 머신 러닝의 목표는 처음 본 데이터에서 잘 작동하는 일반화된 모델을 얻는 것이다.
  - 과대 적합은 큰 장애물이다.

<br>

## 4_2_1. 훈련, 검증, 테스트 세트

- 훈련 세트에서 모델을 훈련하고 검증 세트에서 모델을 평가한다. 테스트 세트에서 최종적으로 딱 한 번 모델을 테스트한다.
- **하이퍼 파라미터** : 층의 수나 층의 유닛 수 등의 파라미터
- 검증 데이터에 맞추어 최적화했기 때문에 검증 데이터에 의도적으로 잘 수행되는 모델이 만들어진다. (테스트 세트는 건드리지 않는다.)
- 데이터를 훈련, 검증, 테스트 세트로 나누는 세 가지 평가 방법으로 단순 홀드아웃 검증 (hold-out validation), K-겹 교차 검증 (K-fold cross-validation), 셔플링(shuffling)을 사용한 반복 K-겹 교차 검증 (iterated K-fold cross-validaion)이 있다.

<br>

### 단순 홀드아웃 검증

- 데이터의 일정량을 테스트 세트로 떼어 놓는다. 
- 남은 데이터에서 훈련하고 테스트 세트로 평가한다.
- **train_test_split()** 코드가 있다.

![image](https://user-images.githubusercontent.com/78655692/148495437-15d1e4c0-46fd-4f2c-939a-ff24a22feb38.png) 이미지출처: [^1]

- 단점 : 데이터가 적을 때는 검증 세트와 테스트 세트의 샘플이 너무 적어 전체 데이터를 통계적으로 대표하지 못할 수 있다.

<br>

### K-겹 교차 검증

- 데이터를 동일한 크기를 가진 K개 분할로 나눈다.
- 각 분할 i에 대해 남은 K-1개의 분할로 모델을 훈련하고 분할 i에서 모델을 평가한다.
- 최종 점수는 얻은 K개의 점수를 평균한다. 

![image](https://user-images.githubusercontent.com/78655692/148495801-5b42bef8-b1d6-4686-ae90-5b5fd3c6117e.png) 이미지출처: [^2]
 
<br>

### 셔플링을 사용한 반복 K-겹 교차 검증

- 비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할 때 사용한다.
- K-겹 교차 검증을 여러 번 적용하되 K개의 분할로 나누기 전에 매번 데이터를 무작위로 섞는다.
- 최종 점수는 모든 K-겹 교차 검증을 실행해서 얻은 점수의 평균이 된다.
- 최종적으로 P x K개(P는 반복 횟수)의 모델을 훈련하고 평가

<br>

## 4_2_2. 기억해야 할 것 

- **대표성 있는 데이터** : 훈련 데이터와 테스트 데이터가 모두 포함되지 않는 현상을 막기 위해서 무작위로 선택하여 데이터 세트를 만듬
- **시간의 방향** : 과거로부터 미래를 예측할 때는 (예) 내일 날씨, 주식 시세) 분할전 무작위로 섞으면 절대 안된다. 
  - 미래의 정보가 누설되므로 테스트 데이터는 무조건 훈련 데이터의 미래여야 한다.
- **데이터 중복** : 훈련 세트와 검증 세트 중복되지 않도록 한다.


<br>

## 4_3_1. 신경망을 위한 데이터 전처리

- **데이터 전처리**의 목적은 주어진 원본 데이터를 신경망에 적용하기 쉽도록 만드는 것이다.
- 벡터화(vectorization), 정규화(normalization), 누락된 값 다루기, 특성 추출 등이 포함

<br>

### 벡터화 

- 신경망에서 모든 입력과 타깃은 부동 소수 데이터로 이루어진 텐서여야 한다.
- 사운드, 이미지, 텍스트 등 처리해야 할 것이 무엇이든지 먼저 텐서로 변환해야 한다.

<br>

### 값 정규화

- 네트워크를 쉽게 학습하기 위한 데이터의 특징
  1. 데이터는 작은 값은 취한다. 일반적으로 대부분의 값이 **0~1** 사이여야 한다.
  2. 균일해야 한다. 모든 특성이 대체로 비슷한 범위를 가져야 한다.

- 엄격한 정규화 방법
  1. 각 특성별로 평균이 0이 되도록 정규화한다.
  2. 각 특성별로 표준 편차가 1이 되도록 정규화한다.

<br>

### 누락된 값 다루기

- 훈련 샘플의 일부를 여러벌 복사해서 테스트 데이터에서 빠질 것 같은 특성을 제거한다. 
  - 사전에 0이 신경망이 정의된 값이 아니면 누락된 값을 0 입력해도 괜찮다. (0으로 처리된 네트워크 학습시 무시하기 시작)
  - 훈련 데이터세트, 테스트 데이터세트에 둘다 누락된 값을 동일하게 넣어주어야 한다.

<br>

### 특성 공학

- 모델에 데이터를 주입하기 전에 하드코딩된 변환을 적용하여 알고리즘이 더 잘 수행되도록 만들어 준다.
- 특성을 더 간단한 방식으로 표현하여 문제를 쉽게 만든다.

<br>

## 4_4. 과대적합과 과소적합

- 머신 러닝의 근본적인 이슈는 최적화와 일반화 사이의 줄다리기이다.
- **최적화 (optimization)** : <b><span style="color:red">가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정이다.</span></b>
- **일반화 (generalization)** : <b><span style="color:red">훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지 의미한다.</span></b>
  - 모델을 만드는 목적은 좋은 일반화 성능을 얻는 것이다.
- 더 많은 데이터에서 훈련된 모델은 일반화 성능이 더 뛰어나다.
- **규제** : <b><span style="color:red">과대적합을 피하는 처리 과정</span></b>


<br>

## 4_4_1. 네트워크 크기 축소

- 과대적합을 막는 가장 단순한 방법은 모델에 있는 학습 파라미터의 수를 줄이는 것이다.
  - 파라미터의 수는 층의 수와 각 층의 유닛 수에 의해 결정된다.
- 너무 많은 용량과 충분하지 않은 용량의 절충점을 찾아야 한다.
<br>

## 4_4_2. 가중치 규제 증가 

- **오캄의 면도날**(Occam's razor) : 어떤 것에 대한 두 가지의 설명이 있다면 더 적은 가정이 필요한 간단한 설명이 옳을 것이라는 이론
  - 간단한 모델이 복잡한 모델보다 덜 과대적합될 가능성이 높다.
- 과대적합을 완화하기 위한 일반적인 방법은 네트워크의 **복잡도에 제한을 두어 가중치가 작은 값을 가지도록 강제하는 것**. 가중치 값의 분포가 더 균일하게 된다. (**가중치 규제**)
  - 네트워크의 손실 함수에 큰 가중치에 연관된 비용을 추가한다. 
  - 두 가지 형태의 비용이 있다.
    1. **L1 규제** : 가중치의 **절댓값**에 비례하는 비용이 추가된다.
    2. **L2 규제** : 가중치의 **제곱**에 비례하는 비용이 추가된다. (=가중치 감쇠(weight decay))
     - 가중치가 커지는 것을 억제

- 케라스에서 가중치 규제 객체를 층의 키워드 매개변수로 전달하여 가중치 규제를 추가할 수 있다.

<script src="https://gist.github.com/ingu627/c874596cc69151da84cad5932d66a632.js"></script>

- `l2(0.001)` : 가중치 행렬의 모든 원소를 제곱하고 0.001을 곱하여 네트워크의 전체 손실에 더해진다는 의미.
  - 이 페널티 항은 훈련할 때만 추가된다.

<br>

### 드롭아웃(dropout)

- 뉴런의 연결을 임의로 삭제하는 것
- 네트워크 층에 드롭아웃을 적용하면 훈련하는 동안 무작위로 층의 일부 출력 특성을 제외시킨다.
- **층의 출력 값에 노이즈를 추가하여 중요하지 않은 우연한 패턴을 깨뜨리는 것이다.**
  - 노이즈가 없다면 네트워크가 이 패턴을 기억하기 시작할 것이다.
- 케라스에서는 층의 출력 바로 뒤에 Dropout 층을 추가하여 네트워크에 드롭아웃을 적용할 수 있다.
- `model.add(layers.Dropout(0.5))`

![image](https://user-images.githubusercontent.com/78655692/148497214-0585ef37-460b-41db-8069-0d068ceef3d4.png)

<br>

### 신경망에서 과대적합을 방지하는 방법 

1. 훈련 데이터를 더 모은다.
2. 네트워크의 용량을 감소시킨다.
3. 가중치 규제를 추가한다.
4. 드롭아웃을 추가한다.

<br>

## 4_5. 보편적인 머신 러닝 작업 흐름

## 4_5_1. 문제 정의와 데이터셋 수집

- 주어진 문제 정의
- 입력과 출력이 무엇인지와 어떤 데이터를 사용할 것인지 안다.

<br>

## 4_5_2. 성공 지표 선택

- 정확도, 정밀도, 재현율 등의 성공지표가 모델의 최적화할 손실 함수 선택의 기준이 된다.
- 클래스 분포가 균일한 분류 문제에서 정확도와 ROC AUC가 일반적인 지표
- 클래스 분포가 균일하지 않은 문제에서는 정밀도와 재현율을 사용할 수 있음
- 랭킹 문제나 다중 레이블 문제에는 평균 정밀도를 사용

<br>

## 4_5_3. 평가 방법 선택

- **홀드아웃 검증 세트 분리** : 데이터가 풍부할 때 사용
- **K-겹 교차 검증** : 홀드아웃 검증을 사용하기에 샘플의 수가 너무 적을 때 사용
- **반복 K-겹 교차 검증** : 데이터가 적고 매우 정확한 모델 평가가 필요할 때 사용

<br> 

## 4_5_4. 데이터 준비

- 데이터는 텐서로 구성됨
- 이 텐서에 있는 값은 일반적으로 작은 값으로 스케일 조정되어 있음 
  - 예를 들어 [-1,1] or [0,1] 범위
- 특성마다 범위가 다르면(여러 종류의 값으로 이루어진 데이터라면) 정규화해야 한다.
- 특히 데이터가 적다면 특성 공학을 수행

<br>

## 4_5_5. 기본보다 나은 모델 훈련하기

- 첫 번째 모델을 만들기 위해 중요한 세 가지 선택
  1. **마지막 층의 활성화 함수** : 네트워크의 출력에 필요한 제한을 가한다.
  2. **손실 함수** : 풀려고 하는 문제의 종류에 적합해야 한다.
  3. **최적화 설정** 

- 모델에 맞는 마지막 층의 활성화 함수와 손실 함수 선택

    |문제 유형 | 마지막 층의 활성화 함수 | 손실 함수 |
    | --- | ---| ---|
    |이진 분류 | sigmoid | binary_crossentropy|
    |단일 레이블 다중 분류 | softmax | categorical_crossentropy |
    |다중 레이블 다중 분류 | sigmoid | binary_crossentropy |
    |임의 값에 대한 회귀 | X | mse |
    |0과 1 사이 값에 대한 회귀 | sigmoid | mse 또는 binary_crossentropy |

<br>

## 4_5_6. 몸집 키우기: 과대적합 모델 구축

- 과대적합된 모델 만들기
  1. 층을 추가한다.
  2. 층의 크기를 키운다.
  3. 더 많은 에포크 동안 훈련한다.

<br>

## 4_5_7. 모델 규제와 하이퍼파라미터 튜닝 

- 드롭아웃을 추가한다.
- 층을 추가하거나 제거해서 다른 구조를 시도해 본다.
- L1이나 L2 도는 두 가지 모두 추가한다.
- 최적의 설정을 찾기 위해 하이퍼파라미터를 바꾸어 시도해 본다. (층의 유닛 수나 옵티마이저의 학습률 등)
- 선택적으로 특성 공학을 시도해 본다. 새로운 특성을 추가하거나 유용하지 않을 것 같은 특성을 제거한다.

<br>

## References

- [케라스 창시자에게 배우는 딥러닝](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=173992478)  

[^1]: [4장 머신러닝의 기본 요소 - donaldaq](https://donaldaq.github.io/articles/2018-11/Chapter-4-with-Keras)
[^2]: [4장 머신러닝의 기본 요소 - donaldaq](https://donaldaq.github.io/articles/2018-11/Chapter-4-with-Keras)