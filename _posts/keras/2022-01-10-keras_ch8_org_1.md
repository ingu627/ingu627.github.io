---
layout: single
title: "[케라스(keras) 이해] 8장. 생성 모델을 위한 딥러닝"
excerpt: "케라스 창시자에게 배우는 딥러닝 - LSTM으로 텍스트 생성하기, 딥드림, 뉴런 스타일 트랜스퍼"
categories: keras
tag : [python, keras, DL, API, 딥러닝, 케라스]
toc: true
sidebar_main: true
classes: wide

last_modified_at: 2022-01-11
---

<img align='right' width='200' height='200' src='https://user-images.githubusercontent.com/78655692/147629300-4d7acc5e-225a-454a-92cd-4da82f6828f6.png
'>
본 글은 [케라스 창시자에게 배우는 딥러닝] - (박해선 옮김) 책을 개인공부하기 위해 요약, 정리한 내용입니다. <br>전체 코드는 [https://github.com/ingu627/deep-learning-with-python-notebooks](https://github.com/ingu627/deep-learning-with-python-notebooks)에 기재했습니다.(원본 코드 fork) <br> 뿐만 아니라 책에서 설명이 부족하거나 이해가 안 되는 것들은 외부 자료들을 토대로 메꿔 놓았습니다. 즉, 딥러닝은 이걸로 끝을 내보는 겁니다. <br> 오타나 오류는 알려주시길 바라며, 도움이 되길 바랍니다.
{: .notice--info}

<br>
<br>
<br>
<br>

## 8.1 LSTM으로 텍스트 생성하기

- 순환 신경망으로 시퀀시 데이터를 생성하는 방법을 알아본다.

<br>

### 8.1.2 시퀀스 데이터를 어떻게 생성할까?

- 딥러닝에서 시퀀스 데이터를 생성하는 일반적인 방법은 이전 토큰을 입력으로 사용해서 시퀀스의 다음 1개 또는 몇 개의 토큰을 예측.
- **언어 모델**(language model) : 이전 토큰들이 주어졌을 때 다음 토큰의 확률을 모델링할 수 있는 네트워크
- **과정**
  - 언어 모델은 언어의 통계적 구조인 잠재 공간을 탐색한다.
  - 언어 모델 훈련 후 이 모델에서 샘플링 가능 (새로운 시퀀스 생성)
  - 초기 텍스트 문자열을 주입(= 조건 데이터)학고 새로운 글자나 단어를 생성한다.
  - 생성된 출력은 다시 입력 데이터로 추가된다.
  - 이 과정을 여러 번 반복한다.

![image](https://user-images.githubusercontent.com/78655692/148863003-87495657-e66d-4023-9079-7778536533da.png)

<br>
<br>

### 8.1.3 샘플링 전략의 중요성

- 텍스트를 생성할 때 다음 글자를 선택하는 방법들이 있다.
  - **탐욕적 샘플링**(greedy sampling) : 항상 가장 높은 확률을 가진 글자를 선택
  - **확률적 샘플링**(stochastic sampling) : 다음 글자의 확률 분포에서 샘플링하는 과정에 무작위성을 주입하는 방법

<br>
<br>

### 8.1.4 글자 수준의 LSTM 텍스트 생성 모델 구현

- 19세기 후반 독일의 철학자 니체의 글을 예시를 이용해서 케라스로 구현해보기

<br>

### 데이터 전처리

- 원본 텍스트 파일을 내려받아 파싱하기

```python
from tensorflow.keras import utils
import numpy as np

path = utils.get_file(
    'nietzsche.txt',
    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')
text = open(path).read().lower() # 말물칭를 내려받아 소문자로 바꿔준다.
print('말뭉치 크기:', len(text))

# Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt
# 606208/600901 [==============================] - 1s 2us/step
# 말뭉치 크기: 600893
```

<br>

- 글자 시퀀스 벡터화하기

```python
maxlen = 60 # 60개의 글자로 된 시퀀스 추출
step = 3 # 세 글자씩 건너뛰면서 새로운 시퀀스를 샘플링한다.

sentences = [] # 추출한 시퀀스를 담을 리스트

next_chars = [] # 타깃(시퀀스 다음 글자)을 담을 리스트

for i in range(0, len(text) - maxlen, step):
    sentences.append(text[i: i + maxlen])
    next_chars.append(text[i + maxlen])

print('시퀀스 개수:', len(sentences))  # 200278

chars = sorted(list(set(text))) # 말뭉치에서 고유한 글자를 담은 리스트
print('고유한 글자:', len(chars)) # 58
char_indices = dict((char, char.index(char)) for char in chars) # chars 리스트에 있는 글자와 글자의 인덱스를 매핑한 딕셔너리

print('벡터화...')
# 글자를 원핫 인코딩하여 0과 1의 이진 배열로 바꿔준다.
x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)
y = np.zeros((len(sentences), len(chars)), dtype=np.bool)
for i, sentence in enumerate(sentences):
    for t, char in enumerate(sentence):
        x[i, t, char_indices[char]] = 1
    y[i, char_indices[next_chars[i]]] = 1 
    
```

- 이 문서에서 숫자와 구두점 등을 포함하여 고유한 글자의 수는 57개이다.
- 만들어진 훈련 데이터 x의 크기는 (200278, 60, 57)이고 y의 크기는 (200278, 57)이다.

<br>

### 네트워크 구성

- 다음 글자를 예측하기 위한 단일 LSTM 모델

```python
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.models import Sequential

model = Sequential()
model.add(LSTM(128, input_shape=(maxlen, len(chars))))
model.add(Dense(len(chars), activation='softmax'))
```

<br>

- 모델 컴파일 설정하기

```python
from tensorflow.keras.optimizers import RMSprop

optimizer = RMSprop(lr=0.01)
model.compile(loss='categorical_crossentropy', optimizer=optimizer)
```

<br>

### 언어 모델 훈련과 샘플링

- 훈련된 모델과 시드로 쓰일 간단한 텍스트가 주어지면 다음과 같이 반복하여 새로운 텍스트를 생성한다.
  1. 지금까지 생성된 텍스트를 주입하여 모델에서 다음 글자에 대한 확률 분포를 뽑는다.
  2. 특정 온도로 이 확률 분포의 가중치를 조정한다.
  3. 가중치가 조정된 분포에서 무작위로 새로운 글자를 샘플링한다.
  4. 새로운 글자를 생성된 텍스트의 끝에 추가한다.

<br>

- 모델의 예측이 주어졌을 때 새로운 글자를 샘플링하는 함수

```python
import numpy as np

def sample(preds, temperature=1.0):
    preds = np.asarray(preds).astype('float64')
    preds = np.log(preds) / temperature
    exp_preds = np.exp(preds)
    preds = exp_preds / np.sum(exp_preds)
    probas = np.random.multinomial(1, preds, 1)
    return np.argmax(probas)
```

<br>

- 텍스트 생성 루프

```python
import random
import sys

random.seed(42)
start_index = random.randint(0, len(text) - maxlen - 1)

for epoch in range(1, 60): # 60 에포크 동안 모델 훈련
    print('에포크', epoch)
    model.fit(x, y, batch_size=128, epochs=1) # 데이터에서 한 번만 반복해서 모델 학습
    
    seed_text = text[start_index: start_index + maxlen] # 무작위로 시드 텍스트를 선택한다.
    print('--- 시드 텍스트: "' + seed_text + '"')
    
    for temperature in [0.2, 0.5, 1.0, 1.2]: # 여러 가지 샘플링 온도를 시도
        print('------ 온도:', temperature)
        generated_text = seed_text
        sys.stdout.write(generated_text)
        
        for i in range(400): # 시드 텍스트에서 시작해서 400개의 글자를 생성한다.
            # 원 핫 인코딩으로 바꿈
            sampled = np.zeros((1, maxlen, len(chars)))
            for t, char in enumerate(generated_text): 
                sampled[0, t, char_indices[char]] = 1.

            # 다음 글자를 샘플링
            preds = model.predict(sampled, verbose=0)[0]
            next_index = sample(preds, temperature)
            next_char = chars[next_index]
            
            generated_text += next_char
            generated_text = generated_text[1:]
            
            sys.stdout.write(next_char)
            sys.stdout.flush()
        print()
```

<br>
<br>

## 8_2. 딥드림

- **딥드림**(DeepDream) = 합성곱 신경망이 학습한 표현을 사용하여 예술적으로 이미지를 조작하는 기법
- 딥드림 알고리즘은 컨브넷을 거꾸로 실행하는 컨브넷 필터 시각화 기법과 거의 동일하다.
- 특징
  - 딥드림에서는 특정 필터가 아니라 전체 층의 활성화를 최대화한다. 한꺼번에 많은 특성을 섞어 시각화한다.
  - 빈 이미지나 노이즈가 조금 있는 입력이 아니라 이미 가지고 있는 이미지를 사용한다.
  - 입력 이미지는 시각 품질을 높이기 위해 여러 다른 스케일(=옥타브(octave))로 처리한다.
    - **옥타브** : 이미지 크기를 일정한 비율로 연속적으로 줄이거나 늘리는 방식

-> **딥드림 과정** : 연속적으로 스케일을 늘리고(옥타브), 스케일이 증가된 이미지에 디테일을 재주입

<br>
<br>

### 8.2.1 케라스 딥드림 구현

- 사전 훈련된 인셉션 V3 모델 로드하기

```python
from tensorflow.keras.applications import inception_v3
from tensorflow.keras import backend as K

K.set_learning_phase(0) # 모델 훈련 연산을 비활성화

model = inception_v3.InceptionV3(weights='imagenet',
                                 include_top=False)
```

<br>

- 딥드림 설정하기
  - 최대화하려는 손실에 층의 활성화가 기여할 양을 정한다.
  - 층 이름은 내장된 인셉션 V3 애플리케이션에 하드코딩되어 있는 것

```python
layer_contributions = {
    'mixed2': 0.2,
    'mixed3': 3.,
    'mixed4': 2.,
    'mixed5': 1.5,
}
```

<br>

- 최대화할 손실 정의하기

```python
layer_dict = dict([(layer.name, layer) for layer in model.layers])
loss = K.variable(0.) # 손실을 정의하고 각 층의 기여 분을 이 스칼라 변수에 추가
for layer_name in layer_contributions:
    coeff = layer_contributions[layer_name]
    activation = layer_dict[layer_name].output # 층의 출력을 얻는다.
    
    scaling = K.prod(K.cast(K.shape(activation), 'float32'))
    loss = loss + coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling # 층 특성의 L2 노름 제곱을 손실에 추가한다.
```

<br>

- 경사 상승법 과정

```python
import tensorflow as tf

dream = model.input # 생성된 딥드림 이미지 저장

grads = K.gradients(loss, dream)[0] # 손실에 대한 딥드림 이미지의 그래디언트를 계산

grads /= K.maximum(K.mean(K.abs(grads)), 1e-7) # 그래디언트 정규화

outputs = [loss, grads]
fetch_loss_and_grads = K.function([dream], outputs)

def eval_loss_and_grads(x):
    outs = fetch_loss_and_grads([x])
    loss_value = outs[0]
    grad_values = outs[1]
    return loss_value, grad_values

# 이 함수는 경사 상승법을 여러 번 반복하여 수행한다.
def gradient_ascent(x, iterations, step, max_loss=None):
    for i in range(iterations):
        loss_value, grad_values = eval_loss_and_grads(x)
        if max_loss is not None and loss_value > max_loss:
            break
        print('...', i, '번째 손실 :', loss_value)
    return x
```

<br>

- 딥드림 과정

![deep dream process](https://s3.amazonaws.com/book.keras.io/img/ch8/deepdream_process.png)

<br>

- 유틸리티 함수

```python
import scipy
from tensorflow.keras.preprocessing import image

def resize_img(img, size):
    img = np.copy(img)
    factors = (1,
               float(size[0]) / img.shape[1],
               float(size[1]) / img.shape[2],
               1)
    return scipy.ndimage.zoom(img, factors, order=1)

def save_img(img, fname):
    pil_img = deprocess_image(np.copy(img))
    image.save_img(fname, pil_img)

def preprocess_image(image_path): # 사진을 열고 크기를 줄이고 인셉션 V3가 인식하는 텐서 포맷으로 변환하는 유틸리티 함수
    img = image.load_img(image_path)
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = inception_v3.preprocess_input(img)
    return img

def deprocess_image(x): # 넘파일 배열을 적절한 이미지 포맷으로 변환하는 유틸리티 함수
    if K.image_data_format() == 'channels_first':
        x = x.reshape((3, x.shape[2], x.shape[3]))
        x = x.transpose((1, 2, 0))
    else:
        x = x.reshape((x.shape[1], x.shape[2], 3))
    x /= 2.
    x += 0.5
    x *= 255.
    x = np.clip(x, 0, 255).astype('uint8')
    return x
```


<br>

- 연속적인 스케일에 걸쳐 경사 상승법 실행하기

```python
import numpy as np

step = 0.01 # 경사 상승법 단계 크기
num_octave = 3 # 경사 상승법을 실행할 스케일 단계 횟수
octave_scale = 1.4 # 스케일 간의 크기 비율
iterations = 20 # 스케일 단계마다 수행할 경사 상승법 횟수

max_loss = 10. # 손실이 10보다 커지면 이상한 그림이 되기 때문에 경사 상승법 과정을 중지한다.

base_image_path = '../datasets/original_photo_deep_dream.jpg' # 사용할 이미지 경로

img = preprocess_image(base_image_path) # 기본 이미지를 넘파이 배열로 로드

original_shape = img.shape[1:3]
successive_shapes = [original_shape] # 경사 상승법을 실행할 스케일 크기를 정의한 튜플의 리스트를 준비
for i in range(1, num_octave):
    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])
    successive_shapes.append(shape)

successive_shapes = successive_shapes[::-1] # 리스트를 크기 순으로 뒤집는다.

original_img = np.copy(img)
shrunk_original_img = resize_img(img, successive_shapes[0]) # 이미지의 넘파이 배열을 가장 작은 스케일로 변경한다.

for shape in successive_shapes:
    print('처리할 이미지 크기', shape)
    img = resize_img(img, shape)
    img = gradient_ascent(img,
                          iterations=iterations,
                          step=step,
                          max_loss=max_loss)
    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape) # 작게 줄인 원본 이미지의 스케일을 높인다. (픽셀 경계가 보일 것이다.)
    same_size_original = resize_img(original_img, shape) # 이 크기에 해당하는 원본 이미지의 고해상도 버전을 계산한다.
    lost_detail = same_size_original - upscaled_shrunk_original_img # 이 두 이미지의 차이가 스케일을 높였을 때 손실된 디테일
    img += lost_detail # 손실된 디테일을 딥드림 이미지에 다시 주입
    shrunk_original_img = resize_img(original_img, shape)
    save_img(img, fname='dream_at_scale_' + str(shape) + '.png')

save_img(img, fname='./datasets/final_dream.png')
```

<br>

위 코드에서 에러 발생 <br> RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.
{: .notice--danger}

<br>
<br>

## 8.3 뉴럴 스타일 트랜스퍼

![style transfer](https://s3.amazonaws.com/book.keras.io/img/ch8/style_transfer.png)

<br>

- **스타일** : 질감, 색깔, 이미지에 있는 다양한 크기의 시각 요소를 의미
- **콘텐츠** : 이미지에 있는 고수준의 대형 구조





