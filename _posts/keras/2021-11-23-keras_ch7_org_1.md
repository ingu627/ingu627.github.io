---
layout: single
title: "[케라스(keras) 이해] 7장. 딥러닝을 위한 고급 도구 (1)"
excerpt: "케라스 창시자에게 배우는 딥러닝 - 케라스의 함수형 API"
categories: keras
tag : [python, keras, DL, API, 딥러닝, 케라스, 다중 입력 모델, 다중 출력 모델]
toc: true
sidebar_main: true
classes: wide

last_modified_at: 2021-12-29
---

<img align='right' width='200' height='200' src='https://user-images.githubusercontent.com/78655692/147629300-4d7acc5e-225a-454a-92cd-4da82f6828f6.png
'>
본 글은 [케라스 창시자에게 배우는 딥러닝] - (박해선 옮김) 책을 개인공부하기 위해 요약, 정리한 내용입니다. <br>전체 코드는 [https://github.com/ingu627/deep-learning-with-python-notebooks](https://github.com/ingu627/deep-learning-with-python-notebooks)에 기재했습니다.(원본 코드 fork) <br> 뿐만 아니라 책에서 설명이 부족하거나 이해가 안 되는 것들은 외부 자료들을 토대로 메꿔 놓았습니다. 즉, 딥러닝은 이걸로 끝을 내보는 겁니다. <br> 오타나 오류는 알려주시길 바라며, 도움이 되길 바랍니다.
{: .notice--info}

<br>
<br>
<br>
<br>

## 7_1. Sequential 모델을 넘어서: 케라스의 함수형 API 

- 어떤 작업은 입력 데이터에서 여러 개의 타깃 속성을 예측해야 한다.
- 다양한 입력 소스에서 전달된 데이터를 다른 종류의 신경망 층을 사용하여 처리하고 합친다. 

- 다중 입력 모델 

![image](https://user-images.githubusercontent.com/78655692/143162685-86b03cb4-4a55-441f-8827-58556f1eb54b.png)

- 다중 출력 모델 

![image](https://user-images.githubusercontent.com/78655692/143162795-9ed67b9a-53d2-4edf-850a-e434be596f12.png)

- 인셉션 모듈 : 나란히 놓인 합성곱 층으로 구성된 서브그래프

![image](https://user-images.githubusercontent.com/78655692/143162860-c7dba252-539c-457e-a829-d506e563238a.png)

- 잔차 열결 : 하위 층의 출력을 상위 층의 특성 맵에 더해서 아래층의 표현이 네트워크 위쪽으로 흘러갈 수 있도록 한다. 
- 하위 층에서 학습된 정보가 데이터 처리 과정에서 손실되는 것을 방지한다.

![image](https://user-images.githubusercontent.com/78655692/143163083-c8493abf-2538-43e7-9876-6f8d0d2449a9.png)

## 7_1_1. 함수형 API 소개 

- **함수형 API**에서는 직접 텐서들의 입출력을 다룬다. 함수처럼 층을 사용하여 텐서를 입력받고 출력한다.

### Sequential vs 함수형 API

<script src="https://gist.github.com/ingu627/c285efd3938fe081bd9da126ed419187.js"></script>

- 케라스는 input_tensor에서 output_tensor로 가는 데 필요한 모든 층을 추출한다.
- 그 다음 이들을 모아 그래프 데이터 구조인 Model 객체를 만든다.
- 물론 input_tensor를 반복 변환하여 output_tensor를 만들 수 있어야 한다. 관련되지 않은 입력과 출력으로 모델을 만들면 RuntimError가 발생한다.

<script src="https://gist.github.com/ingu627/8865ae1247c88a2fc0083b127974af1a.js"></script>

## 7_1_2. 다중 입력 모델 

- 예시의 모델은 질문-응답 모델이다. 전형적인 질문-응답 모델은 2개의 입력을 가진다.
- (자연어 질문, 답변에 필요한 정보가 담긴 텍스트) 
- 그러면 모델은 답을 출력해야 한다. 가장 간단한 구조는 미리 정의한 어휘 사전에서 소프트맥스 함수를 통해 한 단어로 된 답을 출력하는 것이다.

![image](https://user-images.githubusercontent.com/78655692/143165187-5d882104-4c38-4803-8a01-0d8aef21cae2.png)

### 2개의 입력을 가진 질문-응답 모델의 함수형 API 구현하기

<script src="https://gist.github.com/ingu627/05d44ab6793e515443f7267571a78900.js"></script>

### 다중 입력 모델에 데이터 주입하기 

- 이렇게 입력이 2개인 모델은 2가지 방법을 훈련할 수 있다.
  
1. 넘파이 배열의 리스트에 주입
2. 입력 이름과 넘파이 배열로 이루어진 딕셔너리를 모델의 입력으로 주입 (입력 이름 설정시 가능)

<script src="https://gist.github.com/ingu627/eff1b6517f3629a0e5c1e7cbc1454757.js"></script>

## 7_1_3. 다중 출력 모델 

- 예를 들어 소셜 미디어에서 익명 사용자의 포스트를 입력으로 받아 그 사람의 나이, 성별, 소득 수준 등을 예측한다.

![image](https://user-images.githubusercontent.com/78655692/143170271-99ebebb9-bf5b-4132-b5fa-074561b41060.png)

<script src="https://gist.github.com/ingu627/07e284fe1531a16c96e2ed9be03e5214.js"></script>


### 다중 출력 모델의 컴파일 옵션: 다중 손실 

- 이런 모델을 예측하기 위해서는 네트워크 출력마다 다른 손실 함수를 지정해야 한다. 
- 손실 값을 합치는 가장 간단한 방법은 모두 더하는 것이다. 
- 케라스에서는 compile 메서드에서 리스트나 딕셔너리를 사용하여 출력마다 다른 손실을 지정할 수 있다. 계산된 손실 값은 전체 손실 하나로 더해지고 훈련 과정에서 최소화된다.

<script src="https://gist.github.com/ingu627/73c915acc3f53a34b6370b35a964671e.js"></script>

### 다중 출력 모델의 컴파일 옵션: 손실 가중치

- 손실 값이 최종 손실에 기여하는 수준을 지정할 수 있다.

<script src="https://gist.github.com/ingu627/252990cabd5519608e7a844ddb52d5bc.js"></script>

### 다중 출력 모델에 데이터 주입하기 

- 다중 입력 모델과 마찬가지로 넘파이 배열의 리스트나 딕셔너리를 모델에 전달하여 훈련한다.

<script src="https://gist.github.com/ingu627/6f3fbd903995c9e3fd28661c7b2d3900.js"></script>

## 7_1_4. 층으로 구성된 비순환 유향 그래프

- 함수형 API를 사용하면 다중 입력이나 다중 출력 모델뿐만 아니라 내부 토폴로지가 복잡한 네트워크도 만들 수 있다.
- 케라스의 신경망은 층으로 구성된 어떤 비순환 유향 그래프도 만들 수 있다. 

## 인셉션 모듈 

- **인셉션**은 합성곱 신경망에서 인기 있는 네트워크 구조이다.
- 나란히 분리된 가지를 따라 모듈을 쌓아 독립된 작은 네트워크처럼 구성한다.
- 가장 기본적인 인셉션 모듈 형태는 3~4개의 가지를 가진다.
- 1x1 합성곱으로 시작해섯 3x3 합성곱이 뒤따르고 마지막에 전체 출력 특성이 합쳐진다.
- 이런 구성은 네트워크가 따로따로 공간 특성과 채널 방향의 특성을 학습하도록 돕는다. 

<img src="https://user-images.githubusercontent.com/78655692/143172975-012369c9-5b4c-4c0a-8903-6423c695d752.png" width="500" alt="image">

<script src="https://gist.github.com/ingu627/065ad1963ae7c53b47dbe11b9b83476f.js"></script>

- 위에서 flowchart로 나타낸 모델은 인셉션V3로 케라스에서는 `keras.applications.inception_v3.InceptionV3`에 준비되어 있으며, ImageNet에서 사전 훈련된 가중치를 포함하고 있다. 
- 이와 비슷한 엑셉션 모델도 케라스에 포함되어 있다. 이 합성곱 구조는 채널 방향의 학습과 공간 방향의 학습을 극단적으로 분리한다는 아이디어에 착안하여 인셉션 모듈을 깊이별 분리 합성곱으로 바꾼다. 
- 이 합성곱은 깊이별 합성곱 다음에 점별 합성곱이 뒤따른다. 인셉션 모듈의 극한 형태로 공간 특성과 채널 방향 특성을 완전히 분리한다. 엑셉션은 인셉션V3와 거의 동일한 개수의 모델 파라미터를 가지지만 실행 속도가 더 빠르고 대규모 데이터셋에서 정확도가 더 높다. (효율적 사용)

## 잔차 연결

- **잔차 연결**은 하위 층의 출력을 상위 층의 입력으로 사용한다. 
- 순서대로 놓인 네트워크를 질러가는 연결이 만들어진다. 하위 층의 출력이 상위 층의 출력에 연결되는 것이 아니라 더해진다. 따라서 두 출력의 크기가 동일해야 한다. 크기가 다르면 선형 변환을 사용하여 하위 층의 활성화 출력을 목표 크기로 변환한다.

### 특성 맵의 크기가 다를 때 잔차 연결을 구현

<script src="https://gist.github.com/ingu627/3b2b0e63d94a20f512c3e3cb4a471d45.js"></script>

## 7_1_5. 층 가중치 공유 

- **함수형 API**의 중요한 또 하나의 기능은 층 객체를 여러 번 재사용할 수 있다는 것이다.
- 층 객체를 두 번 호출하면 새로운 층 객체를 만들지 않고 각 호출에 동일한 가중치를 재사용한다. 이런 기능 때문에 공유 가지를 가진 모델을 만들 수 있다.
- 이런 가지는 가중치를 공유하고 같은 연산을 수행한다.
- 다시 말해 같은 표현을 공유하고 이런 표현을 다른 입력에서 함께 학습한다.

### 함수형 APi를 통해 공유 층을 사용하는 모델 

<script src="https://gist.github.com/ingu627/049ed17fba72be2c7734e3dcd32feaf7.js"></script>

## 7_1_6. 층과 모델 

- 함수형 API에서는 모델을 층처럼 사용할 수 있다.


## References 

- [케라스 창시자에게 배우는 딥러닝](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=173992478) 
- [[Keras Study] 7장. 딥러닝을 위한 고급도구](https://subinium.github.io/Keras-7/)

