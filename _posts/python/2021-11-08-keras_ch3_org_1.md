---
layout: single
title: "[케라스(keras) 이해] 3장. 신경망 시작하기 (1)"
excerpt: "케라스 창시자에게 배우는 딥러닝 요약"
categories: python
tag : [python, keras, DL]
toc: true
toc_sticky: true
author_profile: false

last_modified_at: 2021-11-11
---

> 본 글은 [케라스 창시자에게 배우는 딥러닝] 책을 개인공부하기 위해 요약, 정리한 내용입니다.

## 3_1. 신경망의 구조

요소들

- 네트워크(또는 모델)를 구성하는 층
- 입력 데이터와 그에 상응하는 타깃
- 학습에 사용할 피드백 신호를 정의하는 손실 함수
- 학습 진행 방식을 결정하는 옵티마이저

## 3_1_1. 층: 딥러닝의 구성 단위

- **층** : 하나 이상의 텐서를 입력을 받아 하나 이상의 텐서를 출력하는 데이터 처리 모듈
  - 어떤 종류의 층은 상태가 없지만 대부분의 경우 **가중치**라는 층의 상태를 가진다.
- **가중치** : 확률적 경사 하강법에 의해 학습되는 하나 이상의 텐서이며, 여기에 네트워크가 학습한 지식이 담겨 있다. 

### 층이 2D텐서일때

- (samples, features) 크기의 2D텐서가 저장된 간단한 벡터 데이터는 완전 연결층(fully connected layer)이나 밀집 층(dense layer)이라고도 불리는 밀집 연결 층(densely connected layer)에 의해 처리되는 경우가 많다. (**Dense**)

### 층이 3D 텐서일때

- (samples, timesteps, features) 크기의 3D 텐서로 저장된 시퀀스 데이터는 보통 **LSTM** 같은 순환 층(recurrent layer)에 의해 처리된다.

### 층이 4D 텐서일때

- 4D 텐서로 저장되어 있는 이미지 데이터는 일반적으로 2D 합성곱 층(convolution layer)에 의해 처리된다. (**Conv2D**)

<br/>

- **층 호환성(layer compatibility)** : 각 층이 특정 크기의 입력텐서만 받고 특정 크기의 출력 텐서를 반환한다는 사실을 말한다.

![image](https://user-images.githubusercontent.com/78655692/140713986-67e25dcb-0742-4fc3-9da0-1f32a27f110a.png)

## 3_1_2. 모델: 층의 네트워크

- 네트워크 구조는 **가설 공간(hypothesis space)**을 정의한다.
  - 머신 러닝 : 가능성 있는 공간을 사전에 정의하고 피드백 신호의 도움을 받아 입력 데이터에 대한 유용한 변환을 찾는 것
- 네트워크 구조를 선택함으로써 가능성 있는 공간(가설 공간)을 입력 데이터에서 출력 데이터로 매핑하는 일련의 특정 텐서 연산으로 제한하게 된다.

## 3_1_3. 손실 함수와 옵티마이저 : 학습 과정을 조절하는 열쇠

- 네트워크 구조를 정의하고 나면 두 가지를 더 선택해야 한다.
- **손실 함수**(loss function) (= 목적함수(objective function)) : 훈련하는 동안 최소화될 값. 주어진 문제에 대한 성공 지표가 된다.
  - **binary crossentropy** : 2개의 클래스가 있는 분류 문제
  - **categorical crossentropy** : 여러 개의 클래스가 있는 분류 문제
  - **MSE(mean square error)** : 회귀 문제
  - **CTC(connection temporal classfication)** : 시퀀스 학습 문제


- **옵티마이저**(optimizer) : 손실 함수를 기반으로 네트워크가 어떻게 업데이트될지 결정한다.
  - 특정 종류의 확률적 경사 하강법(SGD)을 구현한다.

## 3_2_1. 케라스, 텐서플로, 씨아노, CNTK

- 케라스 : 딥러닝 모델을 만들기 위한 고수준의 구성 요소를 제공하는 모델 수준의 라이브러리
  - 텐서 조작이나 미분 같은 저수준의 연산을 다루지 않는다.
  - 그 대신 케라스의 백엔드 엔진에서 제공하는 최적화되고 특화된 텐서 라이브러리를 사용한다.

## 3_2_2. 케라스를 사용한 개발: 빠르게 둘러보기

- 전형적인 케라스 작업 흐름
    1. 입력 텐서와 타깃 텐서로 이루어진 훈련 데이터를 정의한다.
    2. 입력과 타깃을 매핑하는 층으로 이루어진 네트워크(또는 모델)를 정의한다.
    3. 손실 함수, 옵티마이저, 모니터링하기 위한 측정 지표를 선택하여 학습 과정을 설정한다.
    4. 훈련 데이터에 대해 모델의 fit() 메서드를 반복적으로 호출한다.

## 모델을 정의하는 방법

### 1. Sequential 클래스

- **sequential()** : 가장 자주 사용하는 구조인 층을 순서대로 쌓아 올린 네트워크

![image](https://user-images.githubusercontent.com/78655692/140716645-573e8eff-7f41-43e6-863f-946deba8f23c.png)


### 2. 함수형 API

- 완전히 임의의 구조를 만들 수 있는 비순환 유향 그래프를 만든다.
- 함수형 API를 사용하면 모델이 처리할 데이터 텐서를 만들고 마치 함수처럼 이 텐서에 층을 적용한다.

![image](https://user-images.githubusercontent.com/78655692/140716898-5164ef30-b4c9-478a-99e8-ed41970ec0e5.png)

## 3_4. 영화 리뷰 분류: 이진 분류 예제

## 3_4_1. IMDB 데이터셋

![image](https://user-images.githubusercontent.com/78655692/140731696-65c8a5ba-6d15-4630-9738-844c01f03554.png)

![image](https://user-images.githubusercontent.com/78655692/140731798-8dbee5fc-a819-4d5a-b110-802c2c7f9fb3.png)

- **word_index()** : 단어와 정수 인덱스를 매핑한 딕셔너리 
- `word_index = imdb.get_word_index()`으로 할당

![image](https://user-images.githubusercontent.com/78655692/140732611-28207994-ad62-415d-8bcb-c49419868483.png)

- 정수 인덱스와 단어를 매핑하도록 뒤집는다.

![image](https://user-images.githubusercontent.com/78655692/140733802-751240ac-f40d-4e68-8abd-cba0b9a277c1.png)

- **get(x)** 함수는 x라는 Key에 대응되는 Value를 돌려준다. 앞에서 살펴보았듯이 a.get('name')은 a['name']을 사용했을 때와 동일한 결괏값을 돌려받는다.
  - 매칭이 안되면 `None`으로 반환해준다.
- `reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])`으로 할당

![image](https://user-images.githubusercontent.com/78655692/140734815-e7cfd710-fe31-4270-8ca5-42b4612e6c64.png)

- 리뷰를 디코딩한다. 0,1,2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺀다.
- `decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])` 로 할당

![image](https://user-images.githubusercontent.com/78655692/140735714-1bbc5137-18b1-4ca6-a8c2-d9aed0fb7d7a.png)

## 3_4_2. 데이터 준비

- 신경망에 숫자 리스트를 주입할 수는 없다.
- 리스트를 텐서로 바꿔야 하는 데 2가지 방법이 있다.

1. 같은 길이가 되도록 리스트에 패딩(padding)을 추가하고 (samples, sequence_length) 크기의 정수 텐서로 변환한다. 
- 그 다음 이 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용한다. (=`Embedding`)
1. 리스트를 원-핫 인코딩(one-hot encoding)하여 0과 1의 벡터로 변환한다. 
- 그 다음 부동 소수 벡터 데이터를 다룰 수 있는 Dense 층을 신경망의 첫 번째 층으로 사용한다.

### 원-핫 벡터로 만들기

- `np.zeros((len(), dimension))` : 크기가 (len(), dimension)이고 모든 원소가 0인 행렬을 만든다.

![image](https://user-images.githubusercontent.com/78655692/140749418-19f81c45-c1c2-4afb-9bb1-2e324550e3c9.png)


![image](https://user-images.githubusercontent.com/78655692/140744668-7802705b-b53a-4c54-b9bb-8416ce98c824.png)

## 3_4_3. 신경망 모델 만들기

- `Dense(16, activation='relu')` : Dense 층에 전달한 매개변수(16)은 은닉 유닛(hidden unit)의 개수이다. 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 된다. 
- `output = relu(dot(W, input) + b)` : 16개의 은닉 유닛이 있다는 것은 가중치 행렬 W의 크기가 (input_dimension, 16)이라는 뜻이다.
  - 입력 데이터와 W를 점곱하면 입력 데이터가 16차원으로 표현된 공간으로 투영된다. (그리고 편향 벡터 b를 더하고 relu 연산을 적용한다.)
- 표현 공간의 차원을 '신경망이 내재된 표현을 학습할 때 가질 수 있는 자유도'로 이해할 수 있다.
- 은닉 유닛을 늘리면 신경망이 더욱 복잡한 표현을 학습할 수 있지만 계산 비용이 커지고 원하지 않는 패턴을 학습할 수도 있다.
- **가설 공간** : 입력 데이터를 16차원의 공간으로 바꾸는 가능한 모든 선형 변환의 집합
- 가설 공간을 풍부하게 만들어 층을 깊게 만드는 장점을 살리기 위해서는 비선형성 또는 활성화 함수를 추가해야 한다. 
  - 그중 `relu`는 딥러닝에서 가장 인기 있는 활성화 함수이다.

<br/>

- Dense 층을 쌓을 때 두 가지 중요한 구조상의 결정이 필요하다.

1. 얼마나 많은 층을 사용할 것인가?
2. 각 층에 얼마나 많은 은닉 유닛을 둘 것인가?

### 보편화된 구조

- 16개의 은닉 유닛을 가진 2개의 은닉 층
- 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 세 번째 층

![image](https://user-images.githubusercontent.com/78655692/140744900-4f33a339-5a32-4612-ad60-ed66c125f188.png)

- 3개의 층으로 된 신경망
- 입력 : 벡터로 변환된 텍스트

<br/>

- 마지막으로 손실 함수와 옵티마이저를 선택한다.
- **크로스엔트로피(Crossentropy)** : 확률 분포 간의 차이를 측정 (원본 분포와 예측 분포 사이를 측정)

### 모델 컴파일하기

![image](https://user-images.githubusercontent.com/78655692/140745879-dea86a2d-c18a-45b5-8715-db327923aab7.png)

## 3_4_4. 훈련 검증

### 검증 세트 준비하기

![image](https://user-images.githubusercontent.com/78655692/140746274-f5b65eeb-cd24-483c-8d08-0268d5ec8868.png)

- 이제 모델을 512개의 샘플씩 미니 배치를 만들어 20번의 에포크 동안 훈련시킨다.
  - **에포크(epochs)** : x_train과 y_train 텐서에 있는 모든 샘플에 대해 20번 반복한다.
- 동시에 따로 떼어 놓은 1만 개의 샘플에서 손실과 정확도를 측정한다. validation_data 매개 변수에 검증 데이터를 전달한다.

### 모델 훈련하기

![image](https://user-images.githubusercontent.com/78655692/140747141-7276f67d-4fb0-44fe-8429-7899cfbff988.png)

![image](https://user-images.githubusercontent.com/78655692/140747398-64f4579b-31e7-41e4-a09a-41f36014c7a6.png)

![image](https://user-images.githubusercontent.com/78655692/140747497-ee99138b-19f9-4401-87d7-e15f6ee63a8f.png)

## 훈련 결과 

![image](https://user-images.githubusercontent.com/78655692/140749591-877e4aed-b61f-4cf2-9f5e-2bd1124fa029.png)

- accuracy : 84.9%

### 훈련과 검증 손실 그리기

![image](https://user-images.githubusercontent.com/78655692/140748322-18c0f36a-8983-4ff1-915f-ded2c83e76f3.png)

- `plt.clf()` : 그래프 초기화

![image](https://user-images.githubusercontent.com/78655692/140748666-f38eb884-12a6-4779-8431-3127a735bade.png)

## 3_4_5. 훈련된 모델로 새로운 데이터에 대해 예측하기

- `predict` 메서드를 사용해서 어떤 리뷰가 긍정일 확률을 예측할 수 있다.

![image](https://user-images.githubusercontent.com/78655692/140749757-9f900b63-73d7-4d09-ae37-be42980e99c7.png)

## 정리 

- 원본 데이터를 신경망에 텐서로 주입하기 위해서는 꽤 많은 전처리가 필요하다.
- **(출력 클래스가 2개인) 이진 분류 문제에서 네트워크는 하나의 유닛과 sigmoid 활성화 함수를 가진 Dense 층으로 끝나야 한다. 이 신경망의 출력은 확률을 나타내는 0과 1 사이의 스칼라 값이다.**


## References

- [케라스 창시자에게 배우는 딥러닝](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=173992478)    
- [점프 투 파이썬](https://wikidocs.net/16)