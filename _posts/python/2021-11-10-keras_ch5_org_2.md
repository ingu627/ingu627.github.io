---
layout: single
title: "[케라스(keras) 이해] 5장. 컴퓨터 비전을 위한 딥러닝 (2)"
excerpt: "케라스 창시자에게 배우는 딥러닝 요약"
categories: python
tag : [python, keras, DL, CV]
toc: true
toc_sticky: true
author_profile: false

last_modified_at: 2021-11-11
---

> 본 글은 [케라스 창시자에게 배우는 딥러닝] 책을 개인공부하기 위해 요약, 정리한 내용입니다.

## 5_2. 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기

- 캐글의 데이터 셋 불러오기 : https://www.kaggle.com/c/dogs-vs-cats/data

<script src="https://gist.github.com/ingu627/163473deb65aec21af5810c38bc943e5.js"></script>

- `os.mkdir()` : 해당 주소에 폴더를 만든다.
- `shutil.rmtree` : 재귀적으로 폴더를 지운다. (존재하면)

<br/>

<script src="https://gist.github.com/ingu627/c9bed47f0d590e52549a844066b1d01a.js"></script>

- `os.path.join` : str들을 붙여준다.
- `shutil.copyfile(src, dst)` : 파일을 src에서 dst로 복사한다.

<br/>

<script src="https://gist.github.com/ingu627/5cfbe9baee00d40f0a62ab63dad3feb6.js"></script>

## 5_2_3. 네트워크 구성하기 

- `Conv2D`와 `MaxPooling2D`층을 번갈아 쌓은 컨브넷을 만든다.
- `Conv2D`와 `MaxPooling2D` 단계를 하나 더 추가하면 네트워크의 용량을 늘리고 Flatten 층의 크기가 너무 커지지 않도록 특성 맵의 크기를 줄일 수 있다.
- 150x150 크기(임의로 선택)의 입력으로 시작해서 Flatten 층 이전에 7x7 크기의 특성 맵으로 줄어든다.
- **특성 맵의 깊이는 네트워크에서 점진적으로 증가하지만(32에서 128까지), 특성 맵의 크기는 감소한다.(150x150에서 7x7)

### 강아지 vs 고양이 분류를 위한 소규모 컨브넷 만들기

<script src="https://gist.github.com/ingu627/a435ef91fdf1a5c4cab16f61b4a9ac05.js"></script>

![image](https://user-images.githubusercontent.com/78655692/141032969-7b4e3533-3f34-412b-9762-26b364cf73bf.png)

### 컨브넷 코드 파헤치기

![cnn1](https://user-images.githubusercontent.com/78655692/141250053-8f8d26c1-13de-465a-9681-42caaae3154d.jpg)

![cnn2](https://user-images.githubusercontent.com/78655692/141253732-d5c4b616-fd55-4ef4-b979-f4c8a8586930.jpg)

1. `model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))` -> (None, 148, 148, 32), param : 896
- `Convolution` : 이미지에 kernel이나 필터를 적용하는 과정
- `input_shape=(150, 150 ,3)`: image_height=150, image_width=150, 그리고 color_channels 는 3을 의미
- `activation='relu'`: relu 는 (Rectified Linear Unit의 약자). 보통 활성화 함수로 쓰이고, input값이 0이하이면 0으로 나타내고, input값이 양수이면 input값을 그대로 나타낸다. 
  - 비선형 문제를 해결하기 위해.
- 인풋값(150,150)이 no-padding을 통해 (148,148,)로 줄어들었다.
- `(3,3)`: kernel이 3x3 격자무늬
- `32` : kernel 필터의 개수 (feature map이라고도 불리는 convolution 채널을 총 32개 가지게 된다.)
- `Param`의 의미 : R, G, B각각에 3x3 픽셀 kernel을 적용시켰는데, 3x3x3=27개의 픽셀과, bias kernel을 하나 가진다. 따라서 (27+1)x32=896
  - `parameter` 수 : (노드의 수) * (input의 차원) + (노드의 수)

2. `model.add(layers.MaxPooling2D((2,2)))` -> (None,74,74,32)
- `MaxPooling` : convoluted 이미지의 최댓값을 줄이는 것(=downsampling)
  - 2X2 kernel을 활용해 최댓값을 뽑는 작업
  - feature 개수는 그대로 32개. 이미지의 크기는 반으로 된다.

3. `model.add(layers.Conv2D(64, (3,3), activation='relu'))` -> (None,72,72,64), param : 18496
- `MaxPooling`을 적용한 74x74 feature map은 convoltion 필터를 통과하며 가장자리가 삭제되어 72x72으로 크기가 줄어든다.
- `convolution layer`는 3x3픽셀로 구성된 kernel을 64개 갖는다.
- `Param`의 의미 : 필터의 사이즈가 3x3이고 개수는 32개 -> (3*3*32+1)*64=18496
- 이 과정을 반복

4. `model.add(layers.Flatten())`    
`model.add(layers.Dense(512, activation='relu'))`    
`model.add(layers.Dense(1, activation='sigmoid'))`
- 분류하기 위해 `dense layer`가 필요. 이 레이어는 1차원 벡터를 갖기 때문에, 앞의 convolutional 레이어의 output을 조개야 한다. (=`layers.Flatten()`)
- 고양이와 강아지를 분류하기 때문에 `sigmoid` 함수 사용

### 모델의 훈련 선택

<script src="https://gist.github.com/ingu627/351fb628f5b6af5c4c7c590ae51feefb.js"></script>

## 5_2_4. 데이터 전처리

- JPEG 데이터가 네트워크에 주입하는 과정
    1. 사진 파일을 읽는다.
    2. JPEG 콘텐츠를 RGB 픽세 값으로 디코딩한다.
    3. 그다음 부동 소수 타입의 센서로 변환한다.
    4. 픽셀 값의 스케일을 [0,1] 사이로 조정한다. (**신경망은 작은 입력 값을 선호한다.**)

-> `keras.preprocessing.image`가 이런 단계를 자동으로 처리해준다.
- `ImageDataGenerator` 클래스는 디크스에 있는 이미지 파일을 전처리된 배치 텐처로 자동으로 바꾸어 주는 파이썬 제너레이터(generator)를 만들어 준다.
  - 파이썬 제너레이터(generator) : 특수한 반복자이며 yield 문을 사용하여 만든 경우를 제너레이터 함수, 소괄호와 리스트 내포 구문을 사용하는 경우를 제너레이터 표현식이라고 한다.

### ImageDataGenerator

- `ImageDataGenerator` : 이미지를 학습시킬 때 학습데이터의 양이 적을 경우 학습데이터를 조금씩 변형시켜서 학습데이터의 양을 늘리는 방식중에 하나이다.
  - ImageDataGenerator() - 객체 생성

<script src="https://gist.github.com/ingu627/6c216674682ac773907c86aa90995adb.js"></script>

- `flow_from_directory()` 메서드는 서브 디렉터리의 순서대로 레이블을 할당한다.
  - datagen 이라는 틀에 **flow** 함수를 사용해서 실제 데이터를 파라미터를 넣어주면 이미지 변형이 완료된다.

<script src="https://gist.github.com/ingu627/bf43bb3e009ccb2cc5fdfafc9dd21856.js"></script>

### 제너레이터를 사용한 데이터에 모델을 훈련시키기 

- `fit_generator` 메서드는 fit 메서드와 동일하되 데이터 제너레이터를 사용할 수 있다.
- 이 메서드는 첫 번째 매개변수로 입력과 타깃의 배치를 끝없이 반환하는 파이썬 제너레이터를 기대한다.
- 데이터가 끝없이 생성되기 때문에 케라스 모델에 하나의 에포크를 정의하기 위해 제너레이터로부터 얼마나 많은 샘플을 뽑을 것인지 알려주어야 한다.
  - `steps_per_epoch` 매개변수에서 이를 설정한다.
- 제러네이터부터 `steps_per_epoch`개의 배치만큼 뽑은 후, 즉 `steps_per_epoch` 횟수만큼 경사 하강법 단계를 실행한 후에 훈련 프로세스는 다음 에포크로 넘어간다.
- `validation_data`로 제너레이터를 전달하면 검증 데이터의 배치를 끝없이 반환한다.
- 따라서 검증 데이터 제너레이터에서 얼마나 많은 배치를 추추하여 평가할지 `validation_steps` 매개변수에 지정해야 한다.

<script src="https://gist.github.com/ingu627/e6195a13701f62aa147c6d5d23233c7a.js"></script>

- 훈련이 끝나면 항상 모델을 저장하는 것이 좋다.

<script src="https://gist.github.com/ingu627/c6c16545af1d4c898bad1d29b550b523.js"></script>


<script src="https://gist.github.com/ingu627/05793e4347c8047fb842c1340d944ed0.js"></script>

![image](https://user-images.githubusercontent.com/78655692/141060757-0463d4ad-1679-42e6-9895-fdfa6d474052.png)

## 내용 정리

- 비교적 훈련 샘플의 수(2000개)가 적기 대문에 과대적합이 가장 중요한 문제이다.
- 드롭아웃이나 가중치 감소(L2 규제)처럼 과대적합을 감소시킬 수 있는 방법들이 있다.
- 다음에서는 **데이터 증식**을 시도해 본다.

## References

- [케라스 창시자에게 배우는 딥러닝](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=173992478) 
- [[Tensorflow 2.0] 합성곱 신경망: CNN](https://ericabae.medium.com/tensorflow-2-0-%ED%95%A9%EC%84%B1%EA%B3%B1-%EC%8B%A0%EA%B2%BD%EB%A7%9D-cnn-bfd925298c9b)
- [[이미지 전처리]. ImageDataGenerator 클래스 : 이미지 제너레이터](https://acdongpgm.tistory.com/169)