---
layout: single
title: "[케라스(keras) 이해] 5장. 컴퓨터 비전을 위한 딥러닝 (2)"
excerpt: "케라스 창시자에게 배우는 딥러닝 요약"
categories: python
tag : [python, keras, DL, CV]
toc: true
toc_sticky: true
author_profile: false

last_modified_at: 2021-11-10
---

## 5_2. 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기

- 캐글의 데이터 셋 불러오기 : https://www.kaggle.com/c/dogs-vs-cats/data

<script src="https://gist.github.com/ingu627/163473deb65aec21af5810c38bc943e5.js"></script>

- `os.mkdir()` : 해당 주소에 폴더를 만든다.
- `shutil.rmtree` : 재귀적으로 폴더를 지운다. (존재하면)

<br/>

<script src="https://gist.github.com/ingu627/c9bed47f0d590e52549a844066b1d01a.js"></script>

- `os.path.join` : str들을 붙여준다.
- `shutil.copyfile(src, dst)` : 파일을 src에서 dst로 복사한다.

<br/>

<script src="https://gist.github.com/ingu627/5cfbe9baee00d40f0a62ab63dad3feb6.js"></script>

## 5_2_3. 네트워크 구성하기 

- `Conv2D`와 `MaxPooling2D`층을 번갈아 쌓은 컨브넷을 만든다.
- `Conv2D`와 `MaxPooling2D` 단계를 하나 더 추가하면 네트워크의 용량을 늘리고 Flatten 층의 크기가 너무 커지지 않도록 특성 맵의 크기를 줄일 수 있다.
- 150x150 크기(임의로 선택)의 입력으로 시작해서 Flatten 층 이전에 7x7 크기의 특성 맵으로 줄어든다.
- **특성 맵의 깊이는 네트워크에서 점진적으로 증가하지만(32에서 128까지), 특성 맵의 크기는 감소한다.(150x150에서 7x7)

### 강아지 vs 고양이 분류를 위한 소규모 컨브넷 만들기

<script src="https://gist.github.com/ingu627/a435ef91fdf1a5c4cab16f61b4a9ac05.js"></script>

![image](https://user-images.githubusercontent.com/78655692/141032969-7b4e3533-3f34-412b-9762-26b364cf73bf.png)

### 모델의 훈련 선택

<script src="https://gist.github.com/ingu627/351fb628f5b6af5c4c7c590ae51feefb.js"></script>

## 5_2_4. 데이터 전처리

- JPEG 데이터가 네트워크에 주입하는 과정
    1. 사진 파일을 읽는다.
    2. JPEG 콘텐츠를 RGB 픽세 값으로 디코딩한다.
    3. 그다음 부동 소수 타입의 센서로 변환한다.
    4. 픽셀 값의 스케일을 [0,1] 사이로 조정한다. (**신경망은 작은 입력 값을 선호한다.**)

-> `keras.preprocessing.image`가 이런 단계를 자동으로 처리해준다.
- `ImageDataGenerator` 클래스는 디크스에 있는 이미지 파일을 전처리된 배치 텐처로 자동으로 바꾸어 주는 파이썬 제너레이터(generator)를 만들어 준다.
  - 파이썬 제너레이터(generator) : 특수한 반복자이며 yield 문을 사용하여 만든 경우를 제너레이터 함수, 소괄호와 리스트 내포 구문을 사용하는 경우를 제너레이터 표현식이라고 한다.

<script src="https://gist.github.com/ingu627/6c216674682ac773907c86aa90995adb.js"></script>

- `flow_from_directory()` 메서드는 서브 디렉터리의 순서대로 레이블을 할당한다.

<script src="https://gist.github.com/ingu627/bf43bb3e009ccb2cc5fdfafc9dd21856.js"></script>

### 제너레이터를 사용한 데이터에 모델을 훈련시키기 

- `fit_generator` 메서드는 fit 메서드와 동일하되 데이터 제너레이터를 사용할 수 있다.
- 이 메서드는 첫 번째 매개변수로 입력과 타깃의 배치를 끝없이 반환하는 파이썬 제너레이터를 기대한다.
- 데이터가 끝없이 생성되기 때문에 케라스 모델에 하나의 에포크를 정의하기 위해 제너레이터로부터 얼마나 많은 샘플을 뽑을 것인지 알려주어야 한다.
  - `steps_per_epoch` 매개변수에서 이를 설정한다.
- 제러네이터부터 `steps_per_epoch`개의 배치만큼 뽑은 후, 즉 `steps_per_epoch` 횟수만큼 경사 하강법 단계를 실행한 후에 훈련 프로세스는 다음 에포크로 넘어간다.
- `validation_data`로 제너레이터를 전달하면 검증 데이터의 배치를 끝없이 반환한다.
- 따라서 검증 데이터 제너레이터에서 얼마나 많은 배치를 추추하여 평가할지 `validation_steps` 매개변수에 지정해야 한다.

<script src="https://gist.github.com/ingu627/e6195a13701f62aa147c6d5d23233c7a.js"></script>

- 훈련이 끝나면 항상 모델을 저장하는 것이 좋다.

<script src="https://gist.github.com/ingu627/c6c16545af1d4c898bad1d29b550b523.js"></script>


<script src="https://gist.github.com/ingu627/05793e4347c8047fb842c1340d944ed0.js"></script>

![image](https://user-images.githubusercontent.com/78655692/141060757-0463d4ad-1679-42e6-9895-fdfa6d474052.png)

## 내용 정리

- 비교적 훈련 샘플의 수(2000개)가 적기 대문에 과대적합이 가장 중요한 문제이다.
- 드롭아웃이나 가중치 감소(L2 규제)처럼 과대적합을 감소시킬 수 있는 방법들이 있다.
- 다음에서는 **데이터 증식**을 시도해 본다.

## References

- [케라스 창시자에게 배우는 딥러닝](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=173992478) 