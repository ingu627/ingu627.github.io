---
layout: single
title: "[CS231n] 강의8. Training Neural Networks (4) Regularization, Hyperparameter 리뷰"
excerpt: "본 글은 2021년 4월에 강의한 스탠포드 대학의 Convolutional Neural Networks for Visual Recognition 2021년 강의를 듣고 정리한 내용입니다. Lecture8 신경망 학습 중 규제, 하이퍼파라미터에 대해 정리했습니다."
categories: cs231n
tags: [이미지, cnn, cs231n, 리뷰, 정리, 요약, 정의, 란, 딥러닝, 머신러닝, 드롭아웃, dropout, 규제, regularization, data augmentation, dropconnect, max pooling, stochastic depth, cutout, random crop, mixup, hyperparameter, 의미, 설명]
toc: true 
toc_sticky: true
sidebar_main: false

last_modified_at: 2022-04-24
---

<img align='right' width='400' src='https://user-images.githubusercontent.com/78655692/164892824-f29872ea-f540-478f-9cfc-a7f83747e5d0.png'>
본 글은 2021년 4월에 강의한 스탠포드 대학의 "Convolutional Neural Networks for Visual Recognition" 2021년 강의를 듣고 정리한 내용입니다. <br> 개인 공부 목적으로 작성되었으며, 설명이 맞지 않거나 글 오타가 있으면 알려주시길 바랍니다.
{: .notice--info}

원본 링크 : [cs231n.stanford.edu](http://cs231n.stanford.edu/)<br> 한글 번역 링크 : [aikorea.org - cs231n](http://aikorea.org/cs231n/) <br> 강의 링크 : [youtube - 2017 Spring (English)](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
{: .notice--warning}

<br>
<br>
<br>

## Training Neural Networks 

- 이전 글에서는 옵티마이저와 학습률 스케쥴링에 대해서 알아봤다. 다음은 테스트 에러를 개선시키기 위한 규제, 하이퍼파라미터 선택 등을 알아본다.
  - ~~**Improve your training error**~~ **(Completed)**
    - ~~(Fancier) Optimizers~~ **(Completed)**
    - ~~Learning rate schedules~~ **(Completed)**
  - **Improve your test error**
    - Regularization
    - Choosing Hyperparameters

<br>
<br>

## Improve test error

<img src='https://user-images.githubusercontent.com/78655692/164957638-f51801ea-e79e-42ee-916e-e382b0a0f04f.png' width=650>

- 새로운 데이터가 들어오면 학습 데이터와 검증 데이터 사이의 격차가 크게 날 수 있는데 이 차이를 줄여야 한다.
  - 이 격차가 넓어질수록 **과적합(overfitting)**이 된다는 의미이다.
- 손실함수를 최소화시키기 위해 더 나은 최적화(optimization) 알고리즘을 사용해보았다.
- 하지만 테스트 시 성능을 올리기 위해서는 어떻게 해야 될까?

<br>

<img src='https://user-images.githubusercontent.com/78655692/164964986-21309f42-2e6a-4e55-8a10-840722b45596.png' width=500>

- 한 가지 방법으로 **Early Stopping**이 있다.
  - 검증 데이터가 감소하거나 학습(train)데이터를 훈련시 시간이 너무 오래 걸릴 때 훈련중인 모델을 멈춘다.

<br>

- 또 다른 방법으로 **Model Ensembles**이 있다.
  - 다수의 독립적인 모델을 학습시키고 이들의 평균을 이용하는 것이다.

<br>
<br>

## Regularization

- 단일 모델 성능을 향상시킬 수 있는 방법으로 **규제(Regularization)**이 있다.
- 모델의 어떤 것을 추가하여 학습 데이터에 fit하는 것을 막아주는 역할을 한다.

<br>

- 이전에 L1과 L2를 배웠지만 실제로는 잘 사용하지는 않는다.
- 다음은 규제를 하기 위한 방법들이다.

<br>
<br>

### Dropout

<img src='https://user-images.githubusercontent.com/78655692/164965559-1643fea4-2ec8-4a15-848d-f3b97f2782ea.png' width=500>

- **Dropout**은 forward pass 과정에서 몇몇 뉴런을 0으로 만든다.
  - forward pass 마다 그 모양은 계속 바뀐다.

```python
p = 0.5 # 활성화 확률

def train_step(X):

    # 3 레이어의 forward pass
    H1 = np.maximum(0, np.dot(W1, X) + b1)
    U1 = np.random.rand(*H1.shape) < p # 첫번째 dropout mask
    H1 *= U1 # drop
    H2 = np.maximum(0, np.dot(W2, X) + b2)
    U2 = np.random.rand(*H2.shape) < p # 두번째 dropout mask
    H2 *= U2 # drop
    out = np.dot(W3, H2) + b3

    # backward pass : compute_gradient()
    # perform parameter update : step()
    # ...
```

<br>

<img src='https://user-images.githubusercontent.com/78655692/164965904-777c3109-eab0-4051-92af-7d331049923a.png' width=650>

- **드롭아웃(Dropout)**은 특징(feature) 간의 상호작용을 방지해준다.
  - 모델이 고양이를 예측할 때 다양한 특징들을 고르게 이용할 수 있게 해준다.
- 따라서, 드롭아웃은 과접합을 막아주고 단일 모델로 매개변수를 공유하는 **앙상블(ensemble)** 효과도 가질 수 있다.
  - 각 binary mask는 하나의 모델이 된다.
- Q. FC에서는 드롭아웃을 사용하지만, Conv layer에서는 드롭아웃이 왜 적용이 안 될까?
  - A. 컨볼루션 레이어의 모든 이미지 데이터들이 서로 정보를 공유하기 때문이다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164966062-b00c68eb-bd02-4502-837a-149ce1140835.png' width=650>

- test time으로 넘어왔다.
- 드롭아웃은 출력을 무작위로 만든다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164966106-57bccf93-ba15-45e8-96dd-dd01d43b4696.png' width=650>

- 테스트 시 드롭아웃 확률을 곱한다.

  ```python
  def predict(x):
    # ensembled forward pass
    H1 = np.maximum(0, np.dot(W1, X) + b1) * p # scale the activation
    H2 = np.maximum(0, np.dot(W2, X) + b2) * p # scale the activation
    out = np.dot(W3, H2) + b3
  ```

- 테스트가 학습의 절반밖에 되지 않기 때문에 dropout probability(=p)를 출력에 곱한다.
- 즉, 일부 노드를 무작위로 0으로 만들어주고, 테스트 때는 p를 곱해준다. [^1]

<br>

- 대부분은 **Inverted dropout**를 사용한다.

  ```python
  p = 0.5 # 활성화 확률

  def train_step(X):

      # 3 레이어의 forward pass
      H1 = np.maximum(0, np.dot(W1, X) + b1)
      U1 = np.random.rand(*H1.shape) / p # 첫번째 dropout mask
      H1 *= U1 # drop
      H2 = np.maximum(0, np.dot(W2, X) + b2)
      U2 = np.random.rand(*H2.shape) / p # 두번째 dropout mask
      H2 *= U2 # drop
      out = np.dot(W3, H2) + b3

      # backward pass : compute_gradient()
      # perform parameter update : step()
      # ...

  def predict(x):
      # ensembled forward pass
      H1 = np.maximum(0, np.dot(W1, X) + b1) # no scaling necessary
      H2 = np.maximum(0, np.dot(W2, X) + b2) 
      out = np.dot(W3, H2) + b3
  ```

- 테스트 때 기존의 연산을 이용해 학습시간에 p로 나눠준다.

<br>
<br>

### Summary

- **Training** : 랜덤성을 추가해 **과적합(overfitting)**을 막는다.
  - $y=fw(x,z)$
  - 랜덤 미니 배치의 통계를 사용하여 정규화해준다.
- **Testing** : 랜덤성을 평균화시켜 **일반화(generalization)** 효과를 준다.
  - $y=f(x)=E_z[f(x,z)]=$ $\int p(z)f(x,z)dz$
  - 정규화를 위해 고정 통계(fixed stats)를 사용한다.

<br>
<br>

### Data Augmentation

<img src='https://user-images.githubusercontent.com/78655692/164969406-3b4cd0f9-42d2-4e93-8daa-f9370fa3e2b3.png' width=650>

- 데이터 증식 부분은 [Pytorch 기반 LeNet 구현 및 데이터 증식된 CIFAR10 학습해보기](https://ingu627.github.io/code/LeNet_pytorch/) 글에서 다뤘으므로 생략하겠다.

<br>
<br>

### DropConnect

<img src='https://user-images.githubusercontent.com/78655692/164969630-c00e5239-4171-499b-a5d5-94aae120b714.png' width=500>

- **DropConnect**는 활성화가 아닌 가중치를 임의적으로 0을 만드는 걸 말한다.
  - 가중치를 0으로 만드는 건 training 때 그렇고, testing에는 모든 연결선을 사용한다.

<br>
<br>

### Fractional Max Pooling

<img src='https://user-images.githubusercontent.com/78655692/164969703-3a340622-28e7-4dae-8eb4-4e64c74ed5ea.png' width=600>

- **Fractional Max Pooling**은 풀링이 될 지역을 랜덤하게 설정하여 sampling 하는 것이다.
  - **Training** : 랜덤화된 풀링 지역을 사용한다.
  - **Testing** : 몇몇 지역의 예측값들을 평균화한다.

<br>
<br>

### Stochastic Depth

<img src='https://user-images.githubusercontent.com/78655692/164969811-671db7d5-389d-4d2c-9c91-00351ea86763.png' width=350 height=450>

- training 때는 일부 레이어를 제외하고 학습을 진행한다. 
- testing 때는 전체 네트워크를 사용한다.

<br>
<br>

### Cutout / Random Crop

<img src='https://user-images.githubusercontent.com/78655692/164969879-691457cd-0ee2-4661-8c59-159dc6bf79bc.png' width=500>

- training 때는 이미지의 지역을 랜덤하게 설정해 0으로 만든다.
- testing 때는 모든 이미지를 사용한다.
- CIFAR 같은 작은 데이터셋은 잘 작동하지만, ImageNet 같은 큰 데이터셋에서는 덜 작동한다고 한다.

<br>
<br>

### Mixup

<img src='https://user-images.githubusercontent.com/78655692/164969990-934a937a-7e16-4b60-b300-0f1ac950df1b.png' width=550>

- training 때는 랜덤하게 이미지를 섞은(blend)것을 학습한다.
- testing 때는 원본 이미지를 사용한다.

<br>
<br>

## Choosing Hyperparameters

- 하이퍼파라미터를 선택하는 건 총 6단계로 살펴봐야 한다.
- 개요는 다음과 같다.

```md
Step 1: Check initial loss
Step 2: Overfit a small sample
Step 3: Find LR that makes loss go down
  - good LR : 1e-1, 1e-2, 1e-3, 1e-4
Step 4: Coarse grid, train for ~1-5 epochs
  - good weight decay : 1e-4, 1e-5, 0
Step 5: Refine grid, train longer
Step 6: Look at loss and accuracy curves
Step 7: GOTO step 5
```

<br>
<br>

### Random Search vs Grid Search

<img src='https://user-images.githubusercontent.com/78655692/165119850-a4164653-0ba2-4150-8fec-d62b98f36633.png' width=650>

- **Grid search**에서 데이터 과학자는 하이퍼 파라미터 값의 그리드를 설정하고 각 조합에 대해 모델과 테스트 데이터에 대한 점수를 훈련한다. [^2]
- **random search**은 하이퍼 파라미터 값의 그리드를 설정하고 랜덤 조합을 선택하여 모델과 점수를 학습한다. [^2]
  - 이렇게 하면 시도되는 매개 변수 조합의 수를 명시적으로 제어할 수 있다.
  - 검색 반복 횟수는 시간 또는 리소스에 따라 설정된다.
- 위의 그림처럼 grid layout에서는 9개의 시도 중 3번의 개별 위치만 테스트한다. random layout에서는 9개의 모든 부분이 고유 값을 탐색한다. 


<br>
<br>
<br>
<br>

## References

[^1]: [[CS231n] Lecture 7 Training Neural Networks II - 남르미누](https://namrmino.tistory.com/entry/CS231n-Lecture-7-Training-Neural-Networks-II)
[^2]: [A Comparison of Grid Search and Randomized Search Using Scikit Learn](https://medium.com/@peterworcester_29377/a-comparison-of-grid-search-and-randomized-search-using-scikit-learn-29823179bc85)