---
layout: single
title: "CS231n 강의 2: 이미지 분류"
excerpt: "본 글은 2021년 4월에 강의한 스탠포드 대학의 Convolutional Neural Networks for Visual Recognition 2021년 강의를 듣고 정리한 내용입니다. Lecture2 이미지 분류에 대해 정리했습니다."
categories: cs231n
tags: [이미지, 분류, data driven approach, nn, knn, l1 거리, l2 거리, 하이퍼파라미터, 교차 검증, 모델, 설명, 선형, cnn, cs231n, 리뷰, 정리, 요약, 정의, 란, 딥러닝, 머신러닝, 장점, 단점, 가중치, 편향, 매개변수, 파라미터, 의미]
toc: true
toc_sticky: true
sidebar_main: false

last_modified_at: 2022-04-24
---

<img align='right' width='400' src='https://user-images.githubusercontent.com/78655692/164489832-314b2ba7-68d5-47b2-8c70-2bb910354474.png'>
본 글은 2021년 4월에 강의한 스탠포드 대학의 "Convolutional Neural Networks for Visual Recognition" 2021년 강의를 듣고 정리한 내용입니다. <br> 개인 공부 목적으로 작성되었으며, 설명이 맞지 않거나 글 오타가 있으면 알려주시길 바랍니다.
{: .notice--info}

원본 링크 : [cs231n.stanford.edu](http://cs231n.stanford.edu/)<br> 한글 번역 링크 : [aikorea.org - cs231n](http://aikorea.org/cs231n/) <br> 강의 링크 : [youtube - 2017 Spring (English)](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
{: .notice--warning}


<br>
<br>
<br>

## Image Classification

- **이미지 분류 문제** : 입력 이미지를 미리 정해진 카테고리 중 하나인 라벨로 분류하는 문제
- **이미지**는 0~255 정수 범위의 값을 가지는 Width(너비) x Height(높이) x Channel(채널)의 크기의 3차원 배열이다.
  - 3은 Red, Green, Blue로 구성된 3개의 채널을 의미

    <img src='https://user-images.githubusercontent.com/78655692/164508308-bed6dafb-b017-4d31-bff9-1b121bdf710f.png' width=550>

<br>

- 하지만, 이미지는 3차원 배열의 값으로 나타내기 때문에 몇 가지 해결해야 할 문제점들이 있다.

### Challenges

1. **시점 변화(Viewpoint variation)**
   - 고양이를 촬영하는 카메라를 조금만 옆으로 옮겨도 모든 픽셀값들은 달라진다.

    ![image](https://user-images.githubusercontent.com/78655692/164509582-f3b20c88-329b-4aee-b849-e1ad5077689a.png)

    <br>

2. **배경 분규(Background Clutter)**
   - 고양이가 배경과 비슷할 때

    ![image](https://user-images.githubusercontent.com/78655692/164510315-db269826-0b89-4b76-a883-693168df95f4.png)

    <br>

3. **조명 상태(Illumination)**
   - 어두울 때, 그림자가 있을 때

    ![image](https://user-images.githubusercontent.com/78655692/164510673-5c130cfe-9f9f-454d-93f4-3eeb1d6b76b6.png)

    <br>

4. **폐색(Occlusion)**
   - 고양이의 일부만 보여지거나 가려질 수 있다.

    ![image](https://user-images.githubusercontent.com/78655692/164510882-51d9f3f7-5a30-4edc-b777-af647937d64d.png)

    <br>

5. **변형(Deformation)**
   - 고양이의 자세는 다양하게 바뀔 수 있다.

    ![image](https://user-images.githubusercontent.com/78655692/164510984-be1dbb6e-f7c9-40a1-b8f9-02503e24c2c7.png)

    <br>

6. **내부클래스의 다양성(Intraclass variation)**
   - 고양이에 따라 다양한 생김새, 크기, 색 등이 전부 다를 수 있다.

    ![image](https://user-images.githubusercontent.com/78655692/164511105-763ab4ae-ae44-426a-82bc-3c827e6ea0e1.png)

    <br>

<br>

<img src='https://user-images.githubusercontent.com/78655692/164984464-cfcee60e-2d46-4890-b49f-e0e9fd069b5e.png' width=650>

- 시도해볼 수 있는 방법으로,
- **그레이디언트(gradient)**에 의한 특정 패턴을 정의하는 것이 있다.
- 이 시도는 **변형(deformation)** 부분에서 큰 이점을 가진다.
- 하지만, **위치(location)**정보의 부족이 단점이다.

<br>

> 결론 : A good image classification model must be invariant to the cross product of all these variations, while simultaneously retaining sensitivity to the inter-class variations.

<br>
<br>

### Data-Driven Approach

- **데이터 기반 방법론(Data-Driven Approach)** : 컴퓨터에게 각 클래스에 대해 많은 예제를 주고 나서 이 예제들을 보고 시각적으로 학습할 수 있는 학습 알고리즘을 개발하는 과정

1. 이미지와 라벨의 데이터셋을 수집한다.
2. 분류기를 학습할 머신 러닝 알고리즘을 사용한다.
3. 분류기를 새로운 이미지에 평가해본다.

<img src='https://user-images.githubusercontent.com/78655692/164570789-493e3ea5-4114-4547-a1b1-eb0cca1cfc0c.png' width=400>

<br>
<br>

## Nearest Neighbor Classifier

- 첫번째 머신러닝 알고리즘으로 NN 분류기가 있다.
  - 우리는 예측은 빨리하는 분류기를 원한다; 하지만 학습은 느려도 괜찮다.
- **최근접 이웃법(Nearest Neighbor; NN)**: 새로운 데이터를 입력 받았을 때 가장 가까이 있는 것이 무엇이냐를 중심으로 새로운 데이터의 종류를 정해주는 알고리즘 [^1]

<br>

- 최근접 이웃 분류기는 테스트 이미지를 위해 모든 학습 이미지와 비교를 하고 라벨 값을 예상한다.
- 한 가지 방법으로 두 개의 이미지가 있고, 그것들을 $I_1, I_2$ 벡터로 나타냈을 때, 벡터 간의 **L1 distance(Manhattan)**를 계산하는 것이 있다.
  - $d_1(I_1,I_2)=\sum_p\Vert I_1^p-I_2^p\Vert$
  - 결과는 모든 픽셀값 차이의 합이다.

    ![image](https://user-images.githubusercontent.com/78655692/164573067-6a37f982-45c1-4927-be11-ada18c8d780c.png)

    <br>

- 다음으로는 두 벡터 간의 **L2 distance(Euclidean)**를 고려할 수도 있다. 
  - $d_2(I_1,I_2)=\sqrt{\sum_p(I_1^p-I_2^p)^2}$

<br>

### k - Nearest Neighbor (kNN)

![image](https://user-images.githubusercontent.com/78655692/164571618-af9e5a24-508d-45b3-9df4-9b15a43716c1.png)

- 색칠된 부분들은 L2 거리를 사용한 분류기를 통해 정해진 **결정 경계(decision boundaries)**이다.

<br>

- 여기서 하이퍼파라미터를 잘 조정해줘야 한다. (2가지 고려)
  1. 어떤 k개 값을 사용해야 좋을까?
  2. 어떤 distance를 사용하는 게 가장 좋을까?

    > 하이퍼파라미터(hyperparameter) : 모델링할 때 사용자가 직접 세팅해주는 값

![image](https://user-images.githubusercontent.com/78655692/164575406-1ed034f5-f488-4fd0-a8cd-450ea4c59350.png)

- 학습 데이터셋을 트레이닝 셋과 검증 셋으로 나누고, 검증 셋을 활용하여 모든 hyperparameter 들을 튜닝하라. 마지막으로 테스트 셋에 대해서는 딱 한 번 돌려보고, 성능을 리포트한다.

<br>

### Cross-Validaion

![image](https://user-images.githubusercontent.com/78655692/164575522-da57abdf-c905-4640-8b08-613c25b7df36.png)

- 학습 데이터셋의 크기가 작을(small) 경우, **교차 검증(cross-validation)**이라는 하이퍼파라미터 튜닝 방법 사용
  - 데이터를 폴드하여 분할.
  - 각 폴드 부분을 검증하여 결과를 평균한다.

<img src='https://user-images.githubusercontent.com/78655692/164575816-a2cff881-062d-492a-b73d-219caabea582.png' width=400>

- 파라미터 k에 대한 5-fold 교차 검증 예시이다.
  - 각 k마다 검증 셋으로 활용한 그룹들에서 5개의 정확도가 나온다.
  - 각각의 점은 단일 결과를 나타낸다.
- 여기서 봤을 때 k가 7일 때 가장 좋은 것 같다.

<br>
<br>

### Pros and Cons

- **NN 분류기**의 장단점이 존재한다.

- Pros
  1. 구현하는 것이 매우 단순하고 쉽다.
  2. 분류기를 학습할 때 단순히 학습 데이터셋을 저장하고 기억만 해놓으면 되기 때문에 **학습 시간이 전혀 소요되지 않는다.**
- Cons
  1. 테스트할 때 모든 학습 데이터 예시들과 비교해야되기 때문에 **계산량(Compute)**이 매우 많아진다.
  2. **특이점(outlier)**에 영향을 많이 받는다.

- 하지만, 픽셀 거리를 따질 때 kNN은 절대 사용하지 않는다.
  - 픽셀의 distance metrics은 정보(information)를 제공하지 않는다.
  - 테스트 시 학습이 매우 느리다.

    ![image](https://user-images.githubusercontent.com/78655692/164576421-9ca58fd2-101e-49f7-8126-46519b360e0f.png)

  - **차원의 저주(curse of dimensionality)**도 있다.

    ![image](https://user-images.githubusercontent.com/78655692/164576473-789ea9fa-20d6-4acb-b497-05ef77942de8.png)

<br>

- **kNN**의 단점이 존재한다.

- Cons
  1. 모든 학습 데이터를 기억해야 하고, 나중에 테스트 데이터와 비교하기 위해 저장해두어야 한다.
  2. 테스트 이미지를 분류할 때 모든 학습 이미지와 다 비교해야되기 때문에 계산량/시간이 많이 소요된다.

<br>
<br>

## Linear Classifier

- 이미지의 픽셀 값들을 각 클래스에 대한 신뢰도 점수(confidence score)로 매핑시켜주는 스코어 함수를 정의한다.
  - $x_i\in R^D$ : 학습 이미지 데이터셋 
    - $D$ : dimension
  - $y_i$ : 각 해당 라벨
  - $K$ : class
- 이미지의 픽셀값들을 클래스 스코어로 매핑해주는 스코어 함수
  - $f:R^D\to R^K$
- **선형 분류기(Linear Classifier)**
  - $f(x_i,W,b)=Wx_i+b$
  - 여기서 쓰이는 **매개변수(parameter)**는 우리가 가지고 있는 학습데이터들의 요약한(summarize) 정보를 가지고 있다. [^2]
  - **편향(bias)**를 더하면 데이터와 독립적을 존재하게 되고, 입력 데이터에 의존하지 않아도 된다.
  - **분류기(classifier)** : 학습데이터를 분류하는 것이 아니라 한번도 보지 못한 데이터를 분류하는 것이 목표 [^2]
  - 즉, 선형 분류기는 파라미터 $W$를 학습시켜 새로운 데이터에 대해서도 잘 분류하기 위해 정의한다.

![image](https://user-images.githubusercontent.com/78655692/164576833-2a0707e0-3e1e-49b7-83e3-ef7b174d19ec.png)

- 이미지의 배열은 32x32x3이다. 이걸 평평하게 만든 값이 3072이고 따라서 x는 3072x1가 된다. 
  - W는 가중치이다. b는 편향(bias)이다. 
- 따라서 계산은 Wx+b = (10x3072)x(3072x1)+(10x1) = 10x1+10x1 = 10x1로, 10개의 숫자가 출력값(=클래스 스코어)로 나오게 된다.

<br>

- 선형 분류기는 클래스 스코어를 이미지의 모든 픽셀 값들의 가중치 합으로 스코어를 계산한다. 
  - 또한 3개의 채널을 모두 고려하는 것도 잊지 말아야 한다.

![image](https://user-images.githubusercontent.com/78655692/164579906-787d7d8e-f144-4290-b197-a710261c20db.png)

<img src='https://user-images.githubusercontent.com/78655692/164580522-cead8329-1b09-45b6-ba3e-444adf2d14cd.png' width=500>

- 위 그림을 보았을 때 입력값은 2x2이다. 이걸 평평하게 만든 것이 4x1이고 [56, 231, 24, 2] 배열이다. 
  - 위 그림은 단일 채널의 예시이다. 채널이 3개이니 위 과정을 3번 반복한 후 각 더해서 평균을 낸 값이 클래스 스코어값이다.
- 계산은 Wx+b = (3x4)x(4x1)+(3x1)이다.

<br>
<br>

### Hard cases for a linear classifier

<img src='https://user-images.githubusercontent.com/78655692/164985462-8520647d-1b88-4d07-888f-3eb687836a3a.png' width=650>

- 선형 분류기가 잘 작동하지 못하는 경우로 3가지가 있다.

1. 사분면에서 반대 위치에 결정 경계(decision boundary)가 있는 경우
2. 원형의 결정 경계가 있는 경우
3. 3개 이상의 독립적인 결정 경계가 있는 경우



<br>
<br>
<br>
<br>

## References

[^1]: [[머신러닝] K-최근접 이웃 - Gom Guard](https://gomguard.tistory.com/51)
[^2]: [cs231n (2017) - lecture2 _ 2 (linear classifier) - Worth spreading](https://worthpreading.tistory.com/46)