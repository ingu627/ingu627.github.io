---
layout: single
title: "[CS231n] 강의5. Convolutional Neural Networks 리뷰"
excerpt: "본 글은 2021년 4월에 강의한 스탠포드 대학의 Convolutional Neural Networks for Visual Recognition 2021년 강의를 듣고 정리한 내용입니다. Lecture5 합성곱 신경망에 대해 정리했습니다."
categories: cs231n
tag : [이미지, cnn, cs231n, 리뷰, 정리, 요약, 정의, 란, 딥러닝, 머신러닝, 활성화 맵, 합성곱, filter, stride, 제로 패딩, local connectivity, 풀링, pooling, max pooling, 의미, 설명]
toc: true 
toc_sticky: true
sidebar_main: true

last_modified_at: 2022-06-16
---

<img align='right' width='400' src='https://user-images.githubusercontent.com/78655692/164730055-82d8bcf2-5dab-42e4-b408-9c7e341fc418.png'>
본 글은 2021년 4월에 강의한 스탠포드 대학의 "Convolutional Neural Networks for Visual Recognition" 2021년 강의를 듣고 정리한 내용입니다. <br> 개인 공부 목적으로 작성되었으며, 설명이 맞지 않거나 글 오타가 있으면 알려주시길 바랍니다.
{: .notice--info}

원본 링크 : [cs231n.stanford.edu](http://cs231n.stanford.edu/)<br> 한글 번역 링크 : [aikorea.org - cs231n](http://aikorea.org/cs231n/) <br> 강의 링크 : [youtube - 2017 Spring (English)](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
{: .notice--warning}

<br>
<br>
<br>

## Convolutional Neural Networks

<img src='https://user-images.githubusercontent.com/78655692/164737585-92325497-c174-4931-9b51-e9e35e3b3d4a.png' width=650>

- 다음 그림은 FC(fully-connected layer)이다. 입력 이미지는 32x32x3 이며, 이를 길게 늘려서 3072x1(3072차원) 벡터로 만들었다.
- 여기에 10x3072 크기의 가중치 $W$와 곱하여(10x3072x3027x1->10x1) activation을 얻는다.
- activation은 10개의 행으로 되어 있고, $Wx$의 내적한 결과이다. 
- 하나의 점은 $W$와 입력 사이의 내적을 취했을 때의 결과를 의미한다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164744878-b7231eb9-7e21-45e4-b45f-152cc8f231ae.png' width=650>

- **Convolution Layer**
- 하지만 합성곱 층은 기존의 공간(spatial) 구조를 보존하는 것이다.
- 기존의 FC 층이 입력 이미지를 길게 늘렸다면, 합성곱 층은 이미지의 구조를 그대로 유지하는 것이 차이점이다.
- 위의 그림에서 5x5x3 필터(filter)는 가중치 $W$가 된다.
- 이 필터가 이미지를 슬라이딩(sliding)하면서 공간적으로 내적(dot product)을 수행한다.
- 필터는 항상 입력의 전체 깊이(depth)만큼 확장된다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164745646-f43b630b-3f40-41e6-920e-d7689b8bc782.png' width=650>

- 필터의 크기가 5x5x3이므로 75만큼 곱셈연산을 수행한다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164746334-7233bbed-19ce-4b91-b9a3-f2739ba55f55.gif' width=550> <br> 이미지출처 [^1]


- 합성곱(convolution)은 필터가 이미지의 촤측 상단부터 슬라이딩하면서 연산한다.
- 필터의 모든 요소들이 내적을 수행하게 되면 하나의 값을 얻는다.
- 계속 슬라이딩을 해서 반복한다.
- 이렇게 나온 값들을 **activation map**에 저장한다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164746915-6d655831-827f-4d96-b278-4f26677575b5.png' width=650>

- 또 다른 필터(파란색 다음 초록색 필터)를 이용하여 위 과정을 반복한다. 
- 그럼 또 다른 같은 크기의 activation map을 얻게 된다.
- 여러 개의 필터를 이용하는 이유는 각 필터마다 서로 다른 특징을 추출하기 위해서이다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164747330-f288e40b-b12c-4af7-91a5-9e2785ff82d4.png' width=650>

- 위 그림에서는 5x5x3 필터를 6개 사용한 결과이다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164747815-f2549556-86ab-40c0-86a5-481a48b6c7e2.png' width=650>

- CNN은 보통 합성곱 층의 연속된 형태를 이루게 된다.
- 따라서, 다른 층으로 넘어가기 전에 activation function을 추가하여 비선형성을 만든다.
- 각 레이어는 여러 개의 필터를 가지고 있으며, 각 필터마다 각각의 activation map을 만든다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164748342-e9e4dea3-c98a-42ad-a5ce-f88dd4e5f3a9.png' width=650>

- 앞쪽에 있는 필터들은 저수준의 특징들을 학습한다. 
- 그러다 고수준의 특징에 가면 객체(ex. 강아지)와 비슷한 특징을 가지고 있는 것을 볼 수 있다.
  - 이는 레이어의 계층에 따라 각기 다르게 특징(feature)을 뽑는다는 것을 의미한다.
- 여러 개의 필터는 레이어 계층들을 통과하고 역전파로 반복되어 학습이 된다.

<br>
<br>

### Spatial Dimensions

<img src='https://user-images.githubusercontent.com/78655692/164751119-f7052cc6-36c7-459b-826e-b2adc8459a35.gif' width=650>

- 이번 섹션에서는 공간 차원에 대해 더 자세히 알아보는 시간을 가진다.
- 위의 이미지를 보았을 때 7x7 입력에 3x3 필터가 있는 것을 확인할 수 있다.
- 필터는 오른쪽으로 한칸씩 슬라이딩하며 내적 값들을 얻는다.
- stride가 1일 경우, 5x5 activation map을 얻는다.
- 두번째 경우는 stride가 2일 경우이다. 
- stride가 2인 의미는 슬라이딩을 2칸씩 건너뛰어서 연산한다는 것이다.
- 결과는 3x3 activation map을 얻는다.
- 하지만, stride가 3일 때는 정수로 맞아 떨어지지 않기 때문에 연산을 진행할 수 없다.
- 여기서 알 수 있는 점은 
  - **출력 크기(output size) = (N - F)/stride +1** 이다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164751899-87fefd0b-b775-4715-9fd6-0f64eb1c3e86.png' width=650>

- **제로 패딩(zero padding)**은 출력 사이즈와 입력 사이즈를 같게 만들거나 이미지의 경계를 포함하는 방법으로 쓰인다.
  - 이미지의 가장자리에 0을 채워 넣는다.
- 공식은 다음과 같다.
  - **(N + 2P - F)/stride +1**

<br>
<br>

### Summary

- 입력이 $W_1\times H_1\times C$라고 가정하고,
- 합성곱 층이 4개의 하이퍼파라미터가 필요로 한다고 하자.
  - $K$ : 필터의 수
  - $F$ : 필터 크기
  - $S$ : 보폭(stirde)
  - $P$ : 제로 패딩(zero padding)
- 우리는 $W_2\times H_2\times K$ 형태로 출력하려면,
  - $W_2=(W_1 - F + 2P)/S + 1$
  - $H_2=(H_1 - F + 2P)/S + 1$
- 그리고, 파라미터의 수는 다음과 같이 계산한다.
  - $KCHW+K$

<br>
<br>

### The brain/neuron view of CONV layer

<img src='https://user-images.githubusercontent.com/78655692/164753935-94b68e99-ee45-4d6f-8ce5-6572bde50d1c.png' width=650>

- 합성곱 층을 뇌의 뉴런 관점에서 생각해 본다.
- 입력 x가 들어오면 가중치 w와 곱하여 하나의 값을 출력한다.
- 하지만, 뉴런은 **로컬 연결성(local connectivity)**를 가지고 있다.
  - 이미지같은 고차원 입력을 다둘 때에는, 현재 레이가 이전의 모든 뉴런들과 연결하는 것은 비효율적이다.
  - 레이어의 각 뉴런을 입력 데이터의 로컬한 영역에만 연결한다.
  - 이 영역을 **receptive field**라 부른다.
- 합성곱 층처럼 슬라이딩하는 것이 아니라 특정 부분에만 연결되어 있다.
- 하나의 뉴런이 한 부분만 처리하게 되고, 이러한 뉴런들이 모여서 전체 이미지를 처리한다.
- 이 공간 구조 그대로 activation map을 만든다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164754449-f0d60ee0-00e6-4688-a964-a4c1f8135bd9.png' width=650>

- activation map은 28x28개의 뉴런 시트이다.
- 출력:
  - 각 activation map은 입력의 작은 영역에 연결된다.
  - 모두 매개 변수를 공유한다.

<br>

<img src='https://user-images.githubusercontent.com/78655692/164754845-0dda300e-2d35-4ff7-9051-419236cd8c50.png' width=650>

- 예를 들어, 5개의 필터가 있는 컨볼루션 레이어는 3D 그리드에 배열된 뉴런으로 구성된다.
- 5개의 서로 다른 뉴런이 입력에서 같은 5개의 영역을 보고 있는 것을 의미한다.
- 따라서 마지막에 이르러, FC layer에 와서는 각 뉴런이 전체 입력 데이터를 보게 된다.

<br>
<br>

## Pooling layer

<img src='https://user-images.githubusercontent.com/78655692/164755411-28b764cd-8cba-4870-bcff-74e4cf7a6ee5.png' width=400>

- **풀링 층(pooling layer)**은 각 활성화 맵(activation map)에 대해 독립적으로 보다 작고 관리하기 쉽게 만들어 준다.
  - 즉, 파라미터 수를 줄이는 과정이다.
  - 공간적 불변성(invariance)을 얻는다.
- 이미지를 downsampling 하여 공간적으로 줄여준다.
  - **downsampling** : 인코딩할 때 데이터의 개수를 줄이는 처리과정 [^2]

<br>
<br>

### Max pooling

<img src='https://user-images.githubusercontent.com/78655692/164755732-58045cdb-4595-4500-aa9d-6b26c4750050.png' width=650>

- 최대 풀링값을 찾는 것이기 때문에 필터 안에서 가장 큰 값을 뽑는다.
- 해당 영역(kernel)내에서 평균 혹은 최대값을 계산하여 요약된 데이터를 만들어낸다. [^2]

<br>
<br>

### Summary

- $W_1\times H_1\times C$ 입력이 있고, 
- 합성곱 층은 2개의 하이퍼 파라미터가 필요로 한다고 가정해보자.
  - $F$ : 공간 범위
  - $S$ : 보폭(stride)
    - 보통 2로 잡는다.
- 우리는 $W_2\times H_2\times C$의 출력값을 얻을 것이다.
  - $W_2=(W_1 - F)/S + 1$
  - $H_2=(H_1 - F)/S + 1$
- 파라미터의 개수는 **0**이다.




<br>
<br>
<br>
<br>

## References

[^1]: [Intuitively Understanding Convolutions for Deep Learning - Irhum Shafkat](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)
[^2]: [한땀한땀 딥러닝 컴퓨터 비전 백과사전 - wikidocs](https://wikidocs.net/147019)
